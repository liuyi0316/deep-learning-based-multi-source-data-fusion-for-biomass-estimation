{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7770503e-1773-499b-ad05-6bf9cc94c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def setup_gpu_memory_growth():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            # 打印异常信息\n",
    "            print(e)\n",
    "\n",
    "# 在程序的开始调用这个函数\n",
    "setup_gpu_memory_growth()\n",
    "\n",
    "# 以下是你的其他TensorFlow代码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c97de78-cfda-4bc7-9da4-30fe33b9bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "# 现在可以运行你的TensorFlow代码了\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e69879ea-c334-48be-81bb-71cc1c288762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbf550a-ac6a-4af0-8df5-bae8c61ab70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e186a1b2-a1f9-460b-9782-86480dc98440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd4362a9-3b08-4cd5-b598-202d1069086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "276a8d4c-cfb1-4522-98fe-e3be71493cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.optimizers as optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cf52d0d-76f5-4169-a99f-15b203edb283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.utils as kutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "05f67543-fb74-4c10-9322-5caf602a4384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a448afae-8eca-4080-bd78-b0372099f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7a0d6d5-0552-4d2b-99e2-d66567e85aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7780987f-98ad-4ebd-9df2-e290724d999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5688abaa-fcf4-4127-bfd5-718ac927d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3725b710-b714-4e25-999c-512b0da7fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b55d69b-7fb1-4504-ae64-1e83ee6ae2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf049ec9-5f02-4b68-a03c-c9acf90560ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31b0bcc2-8d20-4790-8558-5e7e50330c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "83e9b236-84a5-43ba-91be-bbf5c500680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import losses\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0f2490f-869e-4508-a641-472fd9434a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fusion import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5da5afb-9e0c-43f6-a076-618e6fc652ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import fusion  ######改成py！！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a81b1426-509b-4458-95f9-56d8395aca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####optical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2dcb841a-3b21-4616-b826-ed6c9334a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 定义数据集目录\n",
    "BASE_DIR = \"/home/jovyan/private/thesis_data/code/final_code/dataset\"\n",
    "# 假设您有三个不同的目录，分别存储不同类型的图像\n",
    "S1_IMAGE_DIR = os.path.join(BASE_DIR, \"sentinel1_images\")\n",
    "S2_10_IMAGE_DIR = os.path.join(BASE_DIR, \"sentinel2_10_images\")\n",
    "S2_20_IMAGE_DIR = os.path.join(BASE_DIR, \"sentinel2_20_images\")\n",
    "GEDI_IMAGE_DIR = os.path.join(BASE_DIR, \"gedi_4\")\n",
    "LABEL_250_DIR = os.path.join(BASE_DIR, \"LABEL_250_DIR\")\n",
    "LABEL_100_DIR = os.path.join(BASE_DIR, \"LABEL_100_DIR\")\n",
    "\n",
    "\n",
    "# 定义常量\n",
    "\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 1000\n",
    "STEPS = 500\n",
    "\n",
    "# 定义测试和验证图像的文件名\n",
    "# 假设每种类型的图像都有相同的命名方式\n",
    "TRAIN_IMAGES = [\"2.tif\", \"7.tif\", \"4.tif\", \"5.tif\", \"9.tif\", \"12.tif\", \"17.tif\", \"11.tif\"]\n",
    "VAL_IMAGES = [\"6.tif\", \"16.tif\", \"10.tif\",\"15.tif\"]\n",
    "TEST_IMAGES = [\"8.tif\",\"14.tif\", \"3.tif\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3a31e4d1-3eab-4d46-8fc9-e6f3cf00a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_sizes = {\"s1\": (224, 224), \"s2_10\": (224, 224),\"s2_20\":(112,112), \"gedi\": (28, 28), \"LABEL_250_DIR\": (9, 9), \"LABEL_100_DIR\": (23, 23)}\n",
    "bands_count = {\"s1\": 6, \"s2_10\": 4,\"s2_20\":6,\"gedi\":4 }\n",
    "label_dirs = ['LABEL_250_DIR', 'LABEL_100_DIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e0361438-023f-49ab-90ba-62c9996176cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####read multiband image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1398537c-4a34-45aa-9499-f94d047e7096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess_image(image_path, normalise_percentiles=(0.5, 99), is_complex=False):\n",
    "    with rasterio.open(image_path) as image_file:\n",
    "        image_arr = image_file.read()  # 以[通道, 高度, 宽度]格式读取所有波段\n",
    "       \n",
    "        image_arr[image_arr == image_file.nodata] = np.nan\n",
    "                # 如果提供了模板，则应用模板\n",
    "        # if template is not None:\n",
    "        #     image_arr = apply_template(image_arr, template)\n",
    "        \n",
    "        if normalise_percentiles:\n",
    "            for band in range(image_arr.shape[0]):\n",
    "                band_arr = image_arr[band, :, :]\n",
    "                min_value = np.nanpercentile(band_arr, normalise_percentiles[0])\n",
    "                max_value = np.nanpercentile(band_arr, normalise_percentiles[1])\n",
    "                if max_value - min_value > np.finfo(float).eps:\n",
    "                    image_arr[band, :, :] = (band_arr - min_value) / (max_value - min_value)\n",
    "                else:\n",
    "                    image_arr[band, :, :] = np.zeros_like(band_arr)\n",
    "                    \n",
    "                    \n",
    "        if is_complex:\n",
    "            # 对于复数数据的特殊处理\n",
    "            real_channel_1 = np.expand_dims(image_arr[0], axis=0)  # 第一个通道，扩展维度以便堆叠\n",
    "            imag_channel_1 = np.zeros_like(real_channel_1)  # 第一个通道的虚部，使用零填充\n",
    "            \n",
    "            complex_real = np.expand_dims(image_arr[1], axis=0)  # 第二个通道作为复数的实部\n",
    "            complex_imag = np.expand_dims(image_arr[2], axis=0)  # 第三个通道作为复数的虚部\n",
    "            \n",
    "            real_channel_4 = np.expand_dims(image_arr[3], axis=0)  # 第四个通道\n",
    "            imag_channel_4 = np.zeros_like(real_channel_4)  # 第四个通道的虚部，使用零填充\n",
    "            \n",
    "            # 沿通道轴堆叠以创建6个通道\n",
    "            image_arr = np.concatenate([real_channel_1, imag_channel_1, complex_real, complex_imag, real_channel_4, imag_channel_4], axis=0)\n",
    "\n",
    "        # 在返回之前将 NaN 和 Inf 转换为 0\n",
    "        # 此处 posinf 和 neginf 参数可用于指定用于替换正、负无穷的值；默认行为是用最大或最小的浮点数替换\n",
    "        image_arr = np.nan_to_num(image_arr, nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "    return image_arr.transpose(1, 2, 0)  # 重新排序维度为高度 x 宽度 x 通道\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "41120f2c-d4e5-4211-bbe8-e1d215f8880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_single_band_image(image_path, normalise_percentiles=(0, 100)):\n",
    "    with rasterio.open(image_path) as image_file:\n",
    "        image_arr = image_file.read(1)  # Reads the first band\n",
    "        \n",
    "        # Checks and replaces nodata values with np.nan\n",
    "        if image_file.nodata is not None:\n",
    "            image_arr[image_arr == image_file.nodata] = np.nan\n",
    "        \n",
    "        # Applies normalization if needed\n",
    "        if normalise_percentiles:\n",
    "            min_value = np.nanpercentile(image_arr, normalise_percentiles[0])\n",
    "            max_value = np.nanpercentile(image_arr, normalise_percentiles[1])\n",
    "            if max_value - min_value > np.finfo(float).eps:\n",
    "                image_arr = (image_arr - min_value) / (max_value - min_value)\n",
    "            else:\n",
    "                image_arr = np.zeros_like(image_arr)\n",
    "        \n",
    "        # Converts np.nan to 0.0\n",
    "        single_band_image = np.nan_to_num(image_arr, nan=0.0)\n",
    "    \n",
    "    # Adds a channel dimension and returns\n",
    "    return np.expand_dims(single_band_image, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b58aa231-15f6-4e9d-aafe-68338835f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#反归一化：在某些情况下，特别是回归问题中，你可能需要将预测结果“反归一化”回原始的数值范围，以便结果更易于理解和使用。这要求保存归一化过程中使用的参数（如最小值和最大值），以便在预测后进行逆操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79b1d849-272a-4131-96ab-7011035702cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####别忘了patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a504e62d-80ff-4e72-b0a4-3152510cb883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image_to_patch_size(image, patch_size):\n",
    "    height, width, depth = image.shape\n",
    "    patch_height, patch_width = patch_size  # 解包元组，分别获取补丁的高度和宽度\n",
    "\n",
    "    # 计算目标高度和宽度\n",
    "    target_height = patch_height * (height // patch_height + (1 if height % patch_height != 0 else 0))\n",
    "    target_width = patch_width * (width // patch_width + (1 if width % patch_width != 0 else 0))\n",
    "\n",
    "    # 计算填充量\n",
    "    pad_height = (target_height - height) // 2\n",
    "    pad_width = (target_width - width) // 2\n",
    "\n",
    "    # 创建填充后的图像\n",
    "    padded = np.zeros((target_height, target_width, depth), dtype=image.dtype)\n",
    "    padded[pad_height:pad_height + height, pad_width:pad_width + width, :] = image\n",
    "\n",
    "    return padded, (pad_height, pad_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c5e9e41-3a55-43a2-adf5-28748da61a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainSequence(kutils.Sequence):\n",
    "    def __init__(self, filenames, batch_size, patch_sizes, bands_count, len, label_dirs):\n",
    "        self.filenames = filenames\n",
    "        self.batch_size = batch_size\n",
    "        self.patch_sizes = patch_sizes  # 字典，包含每种图像和标签的补丁大小\n",
    "        self.bands_count = bands_count  # 字典，包含每种图像类型的波段数\n",
    "        self.len = len\n",
    "        self.label_dirs = ['LABEL_250_DIR', 'LABEL_100_DIR']  # 列表，包含标签的目录\n",
    "        self.read_dataset()\n",
    "\n",
    "    def read_dataset(self):\n",
    "        self.data = []\n",
    "        for filename in self.filenames:\n",
    "            # 读取和处理图像\n",
    "            s1_image_path = os.path.join(S1_IMAGE_DIR, filename)\n",
    "            s2_10_image_path = os.path.join(S2_10_IMAGE_DIR, filename)\n",
    "            s2_20_image_path = os.path.join(S2_20_IMAGE_DIR, filename)\n",
    "            gedi_image_path = os.path.join(GEDI_IMAGE_DIR, filename)\n",
    "            \n",
    "            #s1_image = read_and_preprocess_image(s1_image_path, normalise=True)\n",
    "            s1_image = read_and_preprocess_image(s1_image_path, is_complex=True)\n",
    "\n",
    "            \n",
    "            s2_10_image = read_and_preprocess_image(s2_10_image_path)\n",
    "            s2_20_image = read_and_preprocess_image(s2_20_image_path)\n",
    "            gedi_image = read_and_preprocess_image(gedi_image_path)\n",
    "            \n",
    "            # Pad each image according to its patch size\n",
    "            s1_image, _ = pad_image_to_patch_size(s1_image, self.patch_sizes['s1'])\n",
    "            s2_10_image, _ = pad_image_to_patch_size(s2_10_image, self.patch_sizes['s2_10'])\n",
    "            s2_20_image, _ = pad_image_to_patch_size(s2_20_image, self.patch_sizes['s2_20'])\n",
    "            gedi_image, _ = pad_image_to_patch_size(gedi_image, self.patch_sizes['gedi'])\n",
    "\n",
    "\n",
    "            images = {'s1': s1_image, 's2_10': s2_10_image, 's2_20':s2_20_image, 'gedi': gedi_image}\n",
    "\n",
    "            # 读取和处理标签\n",
    "            labels = []\n",
    "            for label_type in self.label_dirs:\n",
    "                label_path = os.path.join(BASE_DIR, label_type, filename)\n",
    "                label = read_single_band_image(label_path)\n",
    "                # 使用 label_type 作为键来获取对应的补丁大小\n",
    "                label, _ = pad_image_to_patch_size(label, self.patch_sizes[label_type])\n",
    "                labels.append(label)\n",
    "\n",
    "\n",
    "            self.data.append((images, labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = {key: np.empty((self.batch_size, *self.patch_sizes[key], self.bands_count[key])) for key in ['s1', 's2_10', 's2_20', 'gedi']}\n",
    "        batch_y = [np.empty((self.batch_size, *self.patch_sizes[label_dir], 1)) for label_dir in self.label_dirs]\n",
    "\n",
    "        for patch_index in range(self.batch_size):\n",
    "            images, labels = self.sample_image()\n",
    "\n",
    "            # 基于参考图像（例如s1）计算采样起始点的比例\n",
    "            ref_image = images['s1']\n",
    "            y_ratio, x_ratio = self.calculate_sampling_start_point(ref_image, self.patch_sizes['s1'])\n",
    "\n",
    "            for key, image in images.items():\n",
    "                patch_size = self.patch_sizes[key]\n",
    "                batch_x[key][patch_index] = self.sample_patch(image, patch_size, y_ratio, x_ratio)\n",
    "\n",
    "            for i, label_dir in enumerate(self.label_dirs):\n",
    "                label = labels[i]\n",
    "                label_patch_size = self.patch_sizes[label_dir]\n",
    "                batch_y[i][patch_index] = self.sample_patch(label, label_patch_size, y_ratio, x_ratio)\n",
    "\n",
    "        return [batch_x[key] for key in batch_x], batch_y\n",
    "\n",
    "    def sample_image(self):\n",
    "        # 随机选择一个图像和标签集\n",
    "        image_index = np.random.choice(len(self.data))\n",
    "        selected_data = self.data[image_index]\n",
    "        images = selected_data[0]  # 第一个元素是图像的字典\n",
    "        labels = selected_data[1]  # 第二个元素是标签的列表\n",
    "        # 打印选中的image_index\n",
    "        #print(\"Selected image index:\", image_index)\n",
    "        return images, labels  # 返回图像字典和标签列表\n",
    "\n",
    "    def sample_patch(self, image, patch_size, y_ratio, x_ratio):\n",
    "        # 根据提供的比例和补丁大小采样补丁\n",
    "        height, width, _ = image.shape\n",
    "        y_start = int((height - patch_size[0]) * y_ratio)\n",
    "        x_start = int((width - patch_size[1]) * x_ratio)\n",
    "        return image[y_start:y_start + patch_size[0], x_start:x_start + patch_size[1], :]\n",
    "\n",
    "    def calculate_sampling_start_point(self, reference_image, reference_patch_size):\n",
    "        # 基于参考图像和参考补丁大小计算采样起始点的比例\n",
    "        height, width, _ = reference_image.shape\n",
    "        y_ratio = np.random.uniform(0, 1 - reference_patch_size[0] / height)\n",
    "        x_ratio = np.random.uniform(0, 1 - reference_patch_size[1] / width)\n",
    "        return y_ratio, x_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "598367b1-13cf-4e20-88b8-9c83b9381d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = TrainSequence(TRAIN_IMAGES, BATCH_SIZE, patch_sizes, bands_count, STEPS, label_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a578c81e-e699-45b4-b6df-be480f694e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def check_nan_or_inf_in_batch(data):\n",
    "    #\"\"\"检查批次数据中是否包含NaN或Inf值。\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        # 如果数据是字典类型，则遍历每个键\n",
    "        for key, value in data.items():\n",
    "            if np.any(np.isnan(value)) or np.any(np.isinf(value)):\n",
    "                return True\n",
    "    elif isinstance(data, list):\n",
    "        # 如果数据是列表\n",
    "        for item in data:\n",
    "            if isinstance(item, np.ndarray):\n",
    "                if np.any(np.isnan(item)) or np.any(np.isinf(item)):\n",
    "                    return True\n",
    "            else:\n",
    "                # 对于嵌套的列表或其它结构，需要进一步检查或适当处理\n",
    "                pass\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        # 对于直接的NumPy数组\n",
    "        if np.any(np.isnan(data)) or np.any(np.isinf(data)):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# 假设 train_sequence 是你的 TrainSequence 实例\n",
    "for idx in range(len(train_sequence)):\n",
    "    batch_x, batch_y = train_sequence[idx]  # 获取批次数据\n",
    "    \n",
    "    # 检查特征数据和标签数据中是否有 NaN 或 Inf 值\n",
    "    if check_nan_or_inf_in_batch(batch_x):\n",
    "        print(f\"NaN or Inf detected in features of batch {idx}\")\n",
    "    if check_nan_or_inf_in_batch(batch_y):\n",
    "        print(f\"NaN or Inf detected in labels of batch {idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba09e345-3443-410a-95af-ca1b0e43dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_sequence[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "87ead641-98bd-47ee-83f1-f13fe63990f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对 x 进行检查，这里假设 x 是一个列表或数组的列表\n",
    "for i, item in enumerate(x):\n",
    "    if np.isnan(item).any():\n",
    "        print(f\"NaN value detected in x at index {i}\")\n",
    "\n",
    "# 对 y 进行检查，这里假设 y 是一个列表或数组的列表\n",
    "for i, item in enumerate(y):\n",
    "    if np.isnan(item).any():\n",
    "        print(f\"NaN value detected in y at index {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1155dc11-8334-483c-bd5c-f1cceb9796b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# 打印x的类型和内容示例\n",
    "print(type(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82557aab-bf8b-4bdc-aa92-c42c115518b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # x 是一个列表，y 是一个标签列表的列表\n",
    "# # 假设x中的顺序与bands_count中的键顺序一致\n",
    "\n",
    "# # 计算绘图的总行数：所有输入的波段数 + 所有输出的数量\n",
    "# input_band_count = sum(bands_count.values())\n",
    "# output_label_count = sum(len(labels) for labels in y)\n",
    "# nrows = input_band_count + output_label_count\n",
    "# ncols = 1  # 因为我们只查看第一个批次的数据\n",
    "\n",
    "# fig, axes = plt.subplots(nrows, ncols, figsize=(5, nrows * 2), squeeze=False)\n",
    "\n",
    "# current_row = 0\n",
    "# # 可视化每个输入图像的所有波段\n",
    "# for input_index, (input_key, band_count) in enumerate(bands_count.items()):\n",
    "#     for band_index in range(band_count):\n",
    "#         ax = axes[current_row, 0]\n",
    "#         ax.imshow(x[input_index][0, :, :, band_index], cmap='gray')\n",
    "#         ax.axis('off')\n",
    "#         ax.set_title(f'Input: {input_key}, Band: {band_index + 1}')\n",
    "#         current_row += 1\n",
    "\n",
    "# # 可视化每个输出标签\n",
    "# for label_set_index, label_set in enumerate(y):  # y 是标签列表的列表\n",
    "#     for label_index, label_data in enumerate(label_set):\n",
    "#         ax = axes[current_row, 0]\n",
    "#         ax.imshow(label_data[:, :, 0], cmap='viridis')  # 这里做了修正\n",
    "#         ax.axis('off')\n",
    "#         ax.set_title(f'Output Label Set: {label_set_index + 1}, Label: {label_index + 1}')\n",
    "#         current_row += 1\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77248a4b-9b35-4f67-b91e-da743ee5c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import os\n",
    "# import keras.utils as kutils\n",
    "\n",
    "# class ValSequence(kutils.Sequence):\n",
    "#     def __init__(self, filenames, batch_size, patch_sizes, bands_count, label_dirs):\n",
    "#         self.filenames = filenames\n",
    "#         self.batch_size = batch_size\n",
    "#         self.patch_sizes = patch_sizes\n",
    "#         self.bands_count = bands_count\n",
    "#         self.label_dirs = label_dirs\n",
    "#         self.read_dataset()\n",
    "#         self.reset()\n",
    "\n",
    "#     def read_dataset(self):\n",
    "#         self.data = []\n",
    "#         min_patches_count = None\n",
    "\n",
    "#         for filename in self.filenames:\n",
    "#             # 读取和处理图像\n",
    "#             s1_image_path = os.path.join(S1_IMAGE_DIR, filename)\n",
    "#             s2_10_image_path = os.path.join(S2_10_IMAGE_DIR, filename)\n",
    "#             s2_20_image_path = os.path.join(S2_20_IMAGE_DIR, filename)\n",
    "#             gedi_image_path = os.path.join(GEDI_IMAGE_DIR, filename)\n",
    "            \n",
    "#             #s1_image = read_and_preprocess_image(s1_image_path, normalise=True)\n",
    "#             s1_image = read_and_preprocess_image(s1_image_path, is_complex=True)\n",
    "\n",
    "#             # 然后处理其他图像，并使用S1图像作为模板\n",
    "#             s2_10_image = read_and_preprocess_image(s2_10_image_path)\n",
    "#             s2_20_image = read_and_preprocess_image(s2_20_image_path)\n",
    "#             gedi_image = read_and_preprocess_image(gedi_image_path)\n",
    "            \n",
    "#             images = {'s1': s1_image, 's2_10': s2_10_image, 's2_20':s2_20_image, 'gedi': gedi_image}\n",
    "\n",
    "#             labels = {}\n",
    "#             for label_type in self.label_dirs:\n",
    "#                 label_path = os.path.join(BASE_DIR, label_type, filename)\n",
    "#                 label = read_single_band_image(label_path)\n",
    "#                 labels[label_type] = label\n",
    "\n",
    "\n",
    "#             # Pad images and labels to their respective patch sizes\n",
    "#             for key in images:\n",
    "#                 images[key], _ = pad_image_to_patch_size(images[key], self.patch_sizes[key])\n",
    "#             for key in labels:\n",
    "#                 labels[key], _ = pad_image_to_patch_size(labels[key], self.patch_sizes[key])\n",
    "\n",
    "#             # Calculate patches count for each image and label, then update min_patches_count\n",
    "#             all_sizes = {**images, **labels}  # Combine images and labels for unified processing\n",
    "#             for key, item in all_sizes.items():\n",
    "#                 patch_size = self.patch_sizes[key]\n",
    "#                 patches_count = (item.shape[0] // patch_size[0]) * (item.shape[1] // patch_size[1])\n",
    "#                 if min_patches_count is None or patches_count < min_patches_count:\n",
    "#                     min_patches_count = patches_count\n",
    "\n",
    "#             self.data.append((images, labels))\n",
    "\n",
    "#         self.len = min_patches_count * len(self.filenames) // self.batch_size\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.len\n",
    "    \n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         batch_x = {key: np.empty((self.batch_size, *self.patch_sizes[key], self.bands_count[key])) for key in ['s1', 's2_10', 's2_20', 'gedi']}\n",
    "#         batch_y = {key: np.empty((self.batch_size, *self.patch_sizes[key], 1)) for key in self.label_dirs}\n",
    "\n",
    "#         # 为整个batch计算一个统一的采样起始点\n",
    "#         images, labels = self.data[idx % len(self.data)]\n",
    "#         ref_image = list(images.values())[0]  # 使用第一个图像作为参考\n",
    "#         patch_size = list(self.patch_sizes.values())[0]  # 使用第一个patch size作为参考\n",
    "#         height, width, _ = ref_image.shape\n",
    "#         max_y = height - patch_size[0]\n",
    "#         max_x = width - patch_size[1]\n",
    "#         y = np.random.randint(0, max_y) if max_y > 0 else 0\n",
    "#         x = np.random.randint(0, max_x) if max_x > 0 else 0\n",
    "\n",
    "#         for i in range(self.batch_size):\n",
    "#             for key, image in images.items():\n",
    "#                 batch_x[key][i, ...] = image[y:y + self.patch_sizes[key][0], x:x + self.patch_sizes[key][1], :]\n",
    "#             for key, label in labels.items():\n",
    "#                 batch_y[key][i, ...] = label[y:y + self.patch_sizes[key][0], x:x + self.patch_sizes[key][1], :]\n",
    "\n",
    "#         return [batch_x[key] for key in batch_x], [batch_y[key] for key in batch_y]\n",
    "\n",
    "\n",
    "#     def sample_image(self):\n",
    "#         image_index = np.random.choice(len(self.data))\n",
    "#         return self.data[image_index]\n",
    "\n",
    "#     def reset(self):\n",
    "#         # Resets the sequence to the start\n",
    "#         self.image_index = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe4fb6a1-f4e9-4a03-82f5-0a3199f49b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sequence =TrainSequence(VAL_IMAGES,BATCH_SIZE, patch_sizes, bands_count, STEPS, label_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fb9a3a37-874a-4ac7-8663-ba4b459339ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 train_sequence 是你的 TrainSequence 实例\n",
    "for idx in range(len(val_sequence)):\n",
    "    batch_x, batch_y = val_sequence[idx]  # 获取批次数据\n",
    "    \n",
    "    # 检查特征数据和标签数据中是否有 NaN 或 Inf 值\n",
    "    if check_nan_or_inf_in_batch(batch_x):\n",
    "        print(f\"NaN or Inf detected in features of batch {idx}\")\n",
    "    if check_nan_or_inf_in_batch(batch_y):\n",
    "        print(f\"NaN or Inf detected in labels of batch {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eaa0b135-9bcd-40df-924d-7163186f0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# x,y=val_sequence[1]\n",
    "# # x 是一个列表，y 是一个标签列表的列表\n",
    "# # 假设x中的顺序与bands_count中的键顺序一致\n",
    "\n",
    "# # 计算绘图的总行数：所有输入的波段数 + 所有输出的数量\n",
    "# input_band_count = sum(bands_count.values())\n",
    "# output_label_count = sum(len(labels) for labels in y)\n",
    "# nrows = input_band_count + output_label_count\n",
    "# ncols = 1  # 因为我们只查看第一个批次的数据\n",
    "\n",
    "# fig, axes = plt.subplots(nrows, ncols, figsize=(5, nrows * 2), squeeze=False)\n",
    "\n",
    "# current_row = 0\n",
    "# # 可视化每个输入图像的所有波段\n",
    "# for input_index, (input_key, band_count) in enumerate(bands_count.items()):\n",
    "#     for band_index in range(band_count):\n",
    "#         ax = axes[current_row, 0]\n",
    "#         ax.imshow(x[input_index][0, :, :, band_index], cmap='gray')\n",
    "#         ax.axis('off')\n",
    "#         ax.set_title(f'Input: {input_key}, Band: {band_index + 1}')\n",
    "#         current_row += 1\n",
    "\n",
    "# # 可视化每个输出标签\n",
    "# for label_set_index, label_set in enumerate(y):  # y 是标签列表的列表\n",
    "#     for label_index, label_data in enumerate(label_set):\n",
    "#         ax = axes[current_row, 0]\n",
    "#         ax.imshow(label_data[:, :, 0], cmap='viridis')  # 这里做了修正\n",
    "#         ax.axis('off')\n",
    "#         ax.set_title(f'Output Label Set: {label_set_index + 1}, Label: {label_index + 1}')\n",
    "#         current_row += 1\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a31fe476-c3fa-4398-82fd-838e2ae0b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_sequence = ValSequence(VAL_IMAGES, BATCH_SIZE, patch_sizes, bands_count, label_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "401ead7d-82df-43cf-8558-fc64f4e8d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置输入尺寸\n",
    "input_shape_s1 = 224,224,6  # Sentinel-1 输入尺寸\n",
    "input_shape_s10 = 224,224,4  # Sentinel-2 输入尺寸\n",
    "input_shape_s20 = 112,112,6  # Sentinel-2 输入尺寸\n",
    "input_shape_gedi = 28, 28, 4  # GEDI 输入尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "db6db440-af6d-459b-b694-97dfb21cea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(input_shape_s1, input_shape_s10, input_shape_s20, input_shape_gedi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8e45cb51-0879-4461-a924-8640a28d0c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 112, 112, 6  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)             (None, 112, 112, 64  3520        ['input_2[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 112, 112, 64  256        ['conv2d_26[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 224, 224, 4  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " activation (Activation)        (None, 112, 112, 64  0           ['batch_normalization_26[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)             (None, 112, 112, 64  12608       ['input_3[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)             (None, 112, 112, 64  36928       ['activation[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 112, 112, 64  256        ['conv2d_28[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 112, 112, 64  256        ['conv2d_27[0][0]']              \n",
      " ormalization)                  )                                                                 \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 224, 224, 6  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " activation_2 (Activation)      (None, 112, 112, 64  0           ['batch_normalization_28[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_1 (Activation)      (None, 112, 112, 64  0           ['batch_normalization_27[0][0]'] \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " c_conv2d (CConv2D)             (None, 224, 224, 12  3584        ['input_1[0][0]']                \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 112, 112, 12  0           ['activation_2[0][0]',           \n",
      "                                8)                                'activation_1[0][0]']           \n",
      "                                                                                                  \n",
      " c_batch_norm (CBatchNorm)      (None, 224, 224, 12  512         ['c_conv2d[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 56, 56, 128)  0          ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " c_relu (CRelu)                 (None, 224, 224, 12  0           ['c_batch_norm[0][0]']           \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)             (None, 56, 56, 64)   73792       ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " c_conv2d_1 (CConv2D)           (None, 224, 224, 12  73856       ['c_relu[0][0]']                 \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 56, 56, 64)  256         ['conv2d_29[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " c_batch_norm_1 (CBatchNorm)    (None, 224, 224, 12  512         ['c_conv2d_1[0][0]']             \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " activation_3 (Activation)      (None, 56, 56, 64)   0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " c_relu_1 (CRelu)               (None, 224, 224, 12  0           ['c_batch_norm_1[0][0]']         \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)             (None, 56, 56, 64)   36928       ['activation_3[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)             (None, 56, 56, 64)   8256        ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " c_max_pool2d (CMaxPool2D)      (None, 112, 112, 12  0           ['c_relu_1[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_30 (BatchN  (None, 56, 56, 64)  256         ['conv2d_30[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_31 (BatchN  (None, 56, 56, 64)  256         ['conv2d_31[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " c_conv2d_2 (CConv2D)           (None, 112, 112, 25  147712      ['c_max_pool2d[0][0]']           \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 56, 56, 64)   0           ['batch_normalization_30[0][0]', \n",
      "                                                                  'batch_normalization_31[0][0]'] \n",
      "                                                                                                  \n",
      " c_batch_norm_2 (CBatchNorm)    (None, 112, 112, 25  1024        ['c_conv2d_2[0][0]']             \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " activation_4 (Activation)      (None, 56, 56, 64)   0           ['add[0][0]']                    \n",
      "                                                                                                  \n",
      " c_relu_2 (CRelu)               (None, 112, 112, 25  0           ['c_batch_norm_2[0][0]']         \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)             (None, 56, 56, 64)   36928       ['activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " c_conv2d_3 (CConv2D)           (None, 112, 112, 25  295168      ['c_relu_2[0][0]']               \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " batch_normalization_32 (BatchN  (None, 56, 56, 64)  256         ['conv2d_32[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " c_batch_norm_3 (CBatchNorm)    (None, 112, 112, 25  1024        ['c_conv2d_3[0][0]']             \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " activation_5 (Activation)      (None, 56, 56, 64)   0           ['batch_normalization_32[0][0]'] \n",
      "                                                                                                  \n",
      " c_relu_3 (CRelu)               (None, 112, 112, 25  0           ['c_batch_norm_3[0][0]']         \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)             (None, 56, 56, 64)   36928       ['activation_5[0][0]']           \n",
      "                                                                                                  \n",
      " c_max_pool2d_1 (CMaxPool2D)    (None, 56, 56, 256)  0           ['c_relu_3[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_33 (BatchN  (None, 56, 56, 64)  256         ['conv2d_33[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " c_conv2d_4 (CConv2D)           (None, 56, 56, 512)  590336      ['c_max_pool2d_1[0][0]']         \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 56, 56, 64)   0           ['batch_normalization_33[0][0]', \n",
      "                                                                  'activation_4[0][0]']           \n",
      "                                                                                                  \n",
      " c_batch_norm_4 (CBatchNorm)    (None, 56, 56, 512)  2048        ['c_conv2d_4[0][0]']             \n",
      "                                                                                                  \n",
      " activation_6 (Activation)      (None, 56, 56, 64)   0           ['add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " c_relu_4 (CRelu)               (None, 56, 56, 512)  0           ['c_batch_norm_4[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)             (None, 28, 28, 128)  73856       ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " c_conv2d_5 (CConv2D)           (None, 56, 56, 512)  1180160     ['c_relu_4[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_34 (BatchN  (None, 28, 28, 128)  512        ['conv2d_34[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " c_batch_norm_5 (CBatchNorm)    (None, 56, 56, 512)  2048        ['c_conv2d_5[0][0]']             \n",
      "                                                                                                  \n",
      " activation_7 (Activation)      (None, 28, 28, 128)  0           ['batch_normalization_34[0][0]'] \n",
      "                                                                                                  \n",
      " c_relu_5 (CRelu)               (None, 56, 56, 512)  0           ['c_batch_norm_5[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_7[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)             (None, 28, 28, 128)  8320        ['activation_6[0][0]']           \n",
      "                                                                                                  \n",
      " c_conv2d_6 (CConv2D)           (None, 56, 56, 512)  1180160     ['c_relu_5[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_35 (BatchN  (None, 28, 28, 128)  512        ['conv2d_35[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_36 (BatchN  (None, 28, 28, 128)  512        ['conv2d_36[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " c_batch_norm_6 (CBatchNorm)    (None, 56, 56, 512)  2048        ['c_conv2d_6[0][0]']             \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 28, 28, 128)  0           ['batch_normalization_35[0][0]', \n",
      "                                                                  'batch_normalization_36[0][0]'] \n",
      "                                                                                                  \n",
      " c_relu_6 (CRelu)               (None, 56, 56, 512)  0           ['c_batch_norm_6[0][0]']         \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 28, 28, 128)  0           ['add_2[0][0]']                  \n",
      "                                                                                                  \n",
      " c_max_pool2d_2 (CMaxPool2D)    (None, 28, 28, 512)  0           ['c_relu_6[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " c_conv2d_7 (CConv2D)           (None, 28, 28, 1024  2360320     ['c_max_pool2d_2[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_37 (BatchN  (None, 28, 28, 128)  512        ['conv2d_37[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 28, 28, 4)]  0           []                               \n",
      "                                                                                                  \n",
      " c_batch_norm_7 (CBatchNorm)    (None, 28, 28, 1024  4096        ['c_conv2d_7[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 28, 28, 128)  0           ['batch_normalization_37[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)             (None, 28, 28, 32)   1184        ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " c_relu_7 (CRelu)               (None, 28, 28, 1024  0           ['c_batch_norm_7[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)             (None, 28, 28, 128)  147584      ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 28, 28, 32)  128         ['conv2d_44[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " c_conv2d_8 (CConv2D)           (None, 28, 28, 1024  4719616     ['c_relu_7[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_38 (BatchN  (None, 28, 28, 128)  512        ['conv2d_38[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_15 (Activation)     (None, 28, 28, 32)   0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " c_batch_norm_8 (CBatchNorm)    (None, 28, 28, 1024  4096        ['c_conv2d_8[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 28, 28, 128)  0           ['batch_normalization_38[0][0]', \n",
      "                                                                  'activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)             (None, 28, 28, 32)   9248        ['activation_15[0][0]']          \n",
      "                                                                                                  \n",
      " c_relu_8 (CRelu)               (None, 28, 28, 1024  0           ['c_batch_norm_8[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 28, 28, 128)  0           ['add_3[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_45 (BatchN  (None, 28, 28, 32)  128         ['conv2d_45[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " c_conv2d_9 (CConv2D)           (None, 28, 28, 1024  4719616     ['c_relu_8[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)             (None, 14, 14, 256)  295168      ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_16 (Activation)     (None, 28, 28, 32)   0           ['batch_normalization_45[0][0]'] \n",
      "                                                                                                  \n",
      " c_batch_norm_9 (CBatchNorm)    (None, 28, 28, 1024  4096        ['c_conv2d_9[0][0]']             \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_39[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)             (None, 28, 28, 32)   9248        ['activation_16[0][0]']          \n",
      "                                                                                                  \n",
      " c_relu_9 (CRelu)               (None, 28, 28, 1024  0           ['c_batch_norm_9[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_46 (BatchN  (None, 28, 28, 32)  128         ['conv2d_46[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " c_max_pool2d_3 (CMaxPool2D)    (None, 14, 14, 1024  0           ['c_relu_9[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_11[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)             (None, 14, 14, 256)  33024       ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " activation_17 (Activation)     (None, 28, 28, 32)   0           ['batch_normalization_46[0][0]'] \n",
      "                                                                                                  \n",
      " c_conv2d_10 (CConv2D)          (None, 14, 14, 1024  4719616     ['c_max_pool2d_3[0][0]']         \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_40[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_41[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 14, 14, 32)  0           ['activation_17[0][0]']          \n",
      "                                                                                                  \n",
      " c_batch_norm_10 (CBatchNorm)   (None, 14, 14, 1024  4096        ['c_conv2d_10[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 14, 14, 256)  0           ['batch_normalization_40[0][0]', \n",
      "                                                                  'batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_47 (Conv2D)             (None, 14, 14, 64)   18496       ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " c_relu_10 (CRelu)              (None, 14, 14, 1024  0           ['c_batch_norm_10[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_12 (Activation)     (None, 14, 14, 256)  0           ['add_4[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_47 (BatchN  (None, 14, 14, 64)  256         ['conv2d_47[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " c_conv2d_11 (CConv2D)          (None, 14, 14, 1024  4719616     ['c_relu_10[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " activation_18 (Activation)     (None, 14, 14, 64)   0           ['batch_normalization_47[0][0]'] \n",
      "                                                                                                  \n",
      " c_batch_norm_11 (CBatchNorm)   (None, 14, 14, 1024  4096        ['c_conv2d_11[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_42[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_48 (Conv2D)             (None, 14, 14, 64)   36928       ['activation_18[0][0]']          \n",
      "                                                                                                  \n",
      " c_relu_11 (CRelu)              (None, 14, 14, 1024  0           ['c_batch_norm_11[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " activation_13 (Activation)     (None, 14, 14, 256)  0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_48 (BatchN  (None, 14, 14, 64)  256         ['conv2d_48[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " c_conv2d_12 (CConv2D)          (None, 14, 14, 1024  4719616     ['c_relu_11[0][0]']              \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)             (None, 14, 14, 256)  590080      ['activation_13[0][0]']          \n",
      "                                                                                                  \n",
      " activation_19 (Activation)     (None, 14, 14, 64)   0           ['batch_normalization_48[0][0]'] \n",
      "                                                                                                  \n",
      " c_batch_norm_12 (CBatchNorm)   (None, 14, 14, 1024  4096        ['c_conv2d_12[0][0]']            \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 14, 14, 256)  1024       ['conv2d_43[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " conv2d_49 (Conv2D)             (None, 14, 14, 64)   36928       ['activation_19[0][0]']          \n",
      "                                                                                                  \n",
      " c_relu_12 (CRelu)              (None, 14, 14, 1024  0           ['c_batch_norm_12[0][0]']        \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 14, 14, 256)  0           ['batch_normalization_43[0][0]', \n",
      "                                                                  'activation_12[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_49 (BatchN  (None, 14, 14, 64)  256         ['conv2d_49[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " magnitude_operation (Magnitude  (None, 14, 14, 512)  0          ['c_relu_12[0][0]']              \n",
      " Operation)                                                                                       \n",
      "                                                                                                  \n",
      " activation_14 (Activation)     (None, 14, 14, 256)  0           ['add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 14, 14, 64)   0           ['batch_normalization_49[0][0]'] \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 14, 14, 832)  0           ['magnitude_operation[0][0]',    \n",
      "                                                                  'activation_14[0][0]',          \n",
      "                                                                  'activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_50 (Conv2D)             (None, 14, 14, 128)  958592      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_50 (BatchN  (None, 14, 14, 128)  512        ['conv2d_50[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_50[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_51 (Conv2D)             (None, 14, 14, 128)  147584      ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_51 (BatchN  (None, 14, 14, 128)  512        ['conv2d_51[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_51[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_52 (Conv2D)             (None, 14, 14, 128)  147584      ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_52 (BatchN  (None, 14, 14, 128)  512        ['conv2d_52[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 14, 14, 128)  0           ['batch_normalization_52[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_53 (Conv2D)             (None, 14, 14, 64)   73792       ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_53 (BatchN  (None, 14, 14, 64)  256         ['conv2d_53[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_24 (Activation)     (None, 14, 14, 64)   0           ['batch_normalization_53[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_54 (Conv2D)             (None, 14, 14, 32)   18464       ['activation_24[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_54 (BatchN  (None, 14, 14, 32)  128         ['conv2d_54[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_25 (Activation)     (None, 14, 14, 32)   0           ['batch_normalization_54[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 28, 28, 32)  9248        ['activation_25[0][0]']          \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_56 (BatchN  (None, 28, 28, 32)  128         ['conv2d_transpose[0][0]']       \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_27 (Activation)     (None, 28, 28, 32)   0           ['batch_normalization_56[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_55 (Conv2D)             (None, 9, 9, 32)     36896       ['activation_25[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_56 (Conv2D)             (None, 23, 23, 32)   36896       ['activation_27[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_55 (BatchN  (None, 9, 9, 32)    128         ['conv2d_55[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " batch_normalization_57 (BatchN  (None, 23, 23, 32)  128         ['conv2d_56[0][0]']              \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " activation_26 (Activation)     (None, 9, 9, 32)     0           ['batch_normalization_55[0][0]'] \n",
      "                                                                                                  \n",
      " activation_28 (Activation)     (None, 23, 23, 32)   0           ['batch_normalization_57[0][0]'] \n",
      "                                                                                                  \n",
      " output_250 (Conv2D)            (None, 9, 9, 1)      289         ['activation_26[0][0]']          \n",
      "                                                                                                  \n",
      " output_100 (Conv2D)            (None, 23, 23, 1)    289         ['activation_28[0][0]']          \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 33,887,266\n",
      "Trainable params: 33,863,778\n",
      "Non-trainable params: 23,488\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0bd44d13-edad-41df-a1d1-d9eb79c36f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.engine.functional.Functional object at 0x7efc4871c130>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "48c7539d-632b-4940-847a-7d2719236548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# 自定义损失函数\n",
    "def custom_mse(y_true, y_pred):\n",
    "    eps = K.epsilon()  # 获取一个小常数\n",
    "    return K.mean(K.square(y_pred - y_true) + eps, axis=-1)  # 将小常数加到损失计算中\n",
    "\n",
    "# 定义损失函数字典，使用自定义损失函数\n",
    "losses1 = {\n",
    "    'output_250': custom_mse,  # 使用自定义的损失函数\n",
    "    'output_100': custom_mse   # 同上\n",
    "}\n",
    "\n",
    "# 损失权重保持不变\n",
    "loss_weights1 = {\n",
    "    'output_250': 0.4,\n",
    "    'output_100': 0.6\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8d7ce7cd-e7b1-46e9-be43-26b9b2eca278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses1 = {\n",
    "#     'output_250': 'mean_squared_error',  # 假设这是正确的层名称\n",
    "#     'output_100': 'mean_squared_error'   # 确保这里没有多余的空格\n",
    "# }\n",
    "# loss_weights1 = {\n",
    "#     'output_250': 0.7,\n",
    "#     'output_100': 0.3\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "80e7e7d3-259c-436e-94c9-1e39479b9363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2600c8bc-5b91-455b-aaf9-57efd4206c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义 R² 指标函数\n",
    "def r_squared(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "582dd10a-42cd-4b73-be7f-d69c39303028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class DetectNaNCallback(Callback):\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        weights = self.model.get_weights()\n",
    "        if any(np.isnan(w).any() for w in weights):\n",
    "            print(f'NaN detected in weights at batch {batch}')\n",
    "            self.model.stop_training = True\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        weights = self.model.get_weights()\n",
    "        if any(np.isnan(w).any() for w in weights):\n",
    "            print(f'NaN detected in weights at epoch {epoch}')\n",
    "            self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a4d83790-bcc6-4fee-9d6b-129c56e02ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = keras.optimizers.Adam(1e-3, clipnorm=1, epsilon=1e-4)\n",
    "model.compile(optimizer=optimizer1, loss=losses1, loss_weights=loss_weights1, metrics=['mse',r_squared,'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "082b422b-5843-41f8-8e35-048a10f6cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# 初始化回调函数\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # 监控的值\n",
    "    factor=0.1,          # 学习率减少的因子\n",
    "    patience=5,         # 在减少学习率之前，等待几个epoch\n",
    "    min_lr=0.00001       # 学习率的下限\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8bd02a17-924c-4f02-9126-28b0590601bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "####学习率调整试一下"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9f8f70d2-3445-4791-8f47-93c6f40ac581",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_detect_callback = DetectNaNCallback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "882064df-5071-459a-b732-556f03944aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 定义早停规则\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # 监控的指标，常见的有'val_loss'和'val_accuracy'\n",
    "    min_delta=0.001,  # 表示被监控指标的最小变化量，只有大于这个值时才认为模型有改善\n",
    "    patience=10,  # 指定在监控指标没有改善的情况下等待的epochs数量\n",
    "    verbose=1,  # 控制输出，1表示输出早停信息\n",
    "    mode='min',  # 在监控指标为'val_loss'时，我们希望其最小化，因此设置为'min'。如果监控指标为'val_accuracy'，则设置为'max'\n",
    "    restore_best_weights=True  # 当早停发生时，是否恢复到最好的模型权重\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "06393a2b-7468-427b-b487-48bcb5d131c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# 设置ModelCheckpoint回调函数来保存验证损失最小的模型权重\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='/home/jovyan/private/thesis_data/code/final_code/weight/0410_3_1e-3_best_model_weights.h5',  # 保存文件的路径\n",
    "    save_weights_only=True,  # True表示只保存模型的权重，False则保存整个模型\n",
    "    monitor='val_loss',  # 被监控的数据\n",
    "    mode='min',  # 在'min'模式下，监控数据的减少被认为是改进\n",
    "    save_best_only=True  # True表示只保存在验证集上性能最好的模型\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "9a4fd370-d07e-410f-9472-440d2c05f43c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#正则化，resent，加数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a8272410-468d-4318-b22c-3f6b332578d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_weights('model_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "cf465795-5d86-4a4c-b962-492807fbfc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "500/500 [==============================] - 1491s 2s/step - loss: 0.1005 - output_250_loss: 0.1032 - output_100_loss: 0.0986 - output_250_mse: 0.1032 - output_250_r_squared: -3.7129 - output_250_mae: 0.2542 - output_100_mse: 0.0986 - output_100_r_squared: -3.2182 - output_100_mae: 0.2480 - val_loss: 130.0701 - val_output_250_loss: 178.7653 - val_output_100_loss: 97.6068 - val_output_250_mse: 178.7652 - val_output_250_r_squared: -5198.5967 - val_output_250_mae: 2.1110 - val_output_100_mse: 97.6068 - val_output_100_r_squared: -2332.9124 - val_output_100_mae: 1.4248\n",
      "Epoch 2/100\n",
      "500/500 [==============================] - 895s 2s/step - loss: 0.0701 - output_250_loss: 0.0720 - output_100_loss: 0.0689 - output_250_mse: 0.0720 - output_250_r_squared: -1.4288 - output_250_mae: 0.2165 - output_100_mse: 0.0689 - output_100_r_squared: -1.2772 - output_100_mae: 0.2126 - val_loss: 10.2970 - val_output_250_loss: 15.4057 - val_output_100_loss: 6.8913 - val_output_250_mse: 15.4056 - val_output_250_r_squared: -383.5495 - val_output_250_mae: 1.0794 - val_output_100_mse: 6.8913 - val_output_100_r_squared: -172.5398 - val_output_100_mae: 0.7375\n",
      "Epoch 3/100\n",
      "500/500 [==============================] - 895s 2s/step - loss: 0.0656 - output_250_loss: 0.0673 - output_100_loss: 0.0645 - output_250_mse: 0.0673 - output_250_r_squared: -1.6226 - output_250_mae: 0.2106 - output_100_mse: 0.0645 - output_100_r_squared: -1.4046 - output_100_mae: 0.2058 - val_loss: 4.2442 - val_output_250_loss: 8.6851 - val_output_100_loss: 1.2837 - val_output_250_mse: 8.6851 - val_output_250_r_squared: -386.0043 - val_output_250_mae: 1.0905 - val_output_100_mse: 1.2837 - val_output_100_r_squared: -60.0367 - val_output_100_mae: 0.4484\n",
      "Epoch 4/100\n",
      "500/500 [==============================] - 890s 2s/step - loss: 0.0644 - output_250_loss: 0.0667 - output_100_loss: 0.0629 - output_250_mse: 0.0667 - output_250_r_squared: -1.8574 - output_250_mae: 0.2070 - output_100_mse: 0.0629 - output_100_r_squared: -1.5362 - output_100_mae: 0.2013 - val_loss: 63.8087 - val_output_250_loss: 123.0150 - val_output_100_loss: 24.3379 - val_output_250_mse: 123.0149 - val_output_250_r_squared: -4266.4561 - val_output_250_mae: 4.7714 - val_output_100_mse: 24.3379 - val_output_100_r_squared: -801.5447 - val_output_100_mae: 1.9571\n",
      "Epoch 5/100\n",
      " 40/500 [=>............................] - ETA: 11:28 - loss: 0.0575 - output_250_loss: 0.0608 - output_100_loss: 0.0553 - output_250_mse: 0.0608 - output_250_r_squared: -3.7802 - output_250_mae: 0.1938 - output_100_mse: 0.0553 - output_100_r_squared: -2.9263 - output_100_mae: 0.1873"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [80], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m history\u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m      2\u001b[0m     train_sequence, \n\u001b[1;32m      3\u001b[0m     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      4\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mBATCH_SIZE, \n\u001b[1;32m      5\u001b[0m     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,  \n\u001b[1;32m      6\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39mval_sequence\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m#callbacks=[nan_detect_callback, model_checkpoint_callback,reduce_lr]\u001b[39;00m\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[38;5;241m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[38;5;241m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1410\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stateless_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history= model.fit(\n",
    "    train_sequence, \n",
    "    epochs=100,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=1,  \n",
    "    validation_data=val_sequence\n",
    "    #callbacks=[nan_detect_callback, model_checkpoint_callback,reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e975439d-e6c8-4e3c-8a7d-835b09527865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model training history\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(10, 4))\n",
    "\n",
    "# 绘制损失曲线\n",
    "axs.set_title(\"Sample net training curve loss\")\n",
    "axs.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "axs.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "axs.legend()\n",
    "axs.set_ylabel(\"Loss\")\n",
    "axs.set_xlabel(\"Epoch\")\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f23be98-7ef9-40cb-878c-c25e5693aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 定义一个函数来绘制训练历史曲线\n",
    "def plot_history(metric, val_metric, title, ylabel):\n",
    "    epochs = range(1, len(metric) + 1)\n",
    "    plt.plot(epochs, metric, 'bo-', label='Training ' + title)\n",
    "    plt.plot(epochs, val_metric, 'r+-', label='Validation ' + title)\n",
    "    plt.title('Training and Validation ' + title)\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.legend()\n",
    "\n",
    "# 获取历史数据\n",
    "epochs = range(1, len(history.history['output_250_mse']) + 1)\n",
    "\n",
    "# MSE\n",
    "plt.figure(figsize=(14, 4))\n",
    "plt.subplot(1, 3, 1)\n",
    "plot_history(history.history['output_250_mse'], history.history['val_output_250_mse'], 'MSE (Output 250)', 'MSE')\n",
    "plot_history(history.history['output_100_mse'], history.history['val_output_100_mse'], 'MSE (Output 100)', 'MSE')\n",
    "\n",
    "# R^2\n",
    "plt.subplot(1, 3, 2)\n",
    "plot_history(history.history['output_250_r_squared'], history.history['val_output_250_r_squared'], 'R^2 (Output 250)', 'R^2')\n",
    "plot_history(history.history['output_100_r_squared'], history.history['val_output_100_r_squared'], 'R^2 (Output 100)', 'R^2')\n",
    "\n",
    "# MAE\n",
    "plt.subplot(1, 3, 3)\n",
    "plot_history(history.history['output_250_mae'], history.history['val_output_250_mae'], 'MAE (Output 250)', 'MAE')\n",
    "plot_history(history.history['output_100_mae'], history.history['val_output_100_mae'], 'MAE (Output 100)', 'MAE')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65be8bf-2d09-4e02-b250-ab39e14770d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sequence.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3071b0aa-1df4-404b-b25d-ca85fbb55a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequence =TrainSequence(TEST_IMAGES,BATCH_SIZE, patch_sizes, bands_count, STEPS, label_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6865df81-af9c-4711-9e21-ee6852bdacc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_sequence = ValSequence(TEST_IMAGES, BATCH_SIZE, patch_sizes, bands_count, ['LABEL_250_DIR', 'LABEL_100_DIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941671bd-4709-4604-900e-bb3e3b570707",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_sequence, verbose=1)\n",
    "\n",
    "print(f\"\\nTest loss: {results[0]:.4f}\")\n",
    "print(f\"Output 250 Loss: {results[1]:.4f}\")\n",
    "print(f\"Output 100 Loss: {results[2]:.4f}\")\n",
    "print(f\"Output 250 MSE: {results[3]:.4f}\")\n",
    "print(f\"Output 250 R^2: {results[4]:.4f}\")\n",
    "print(f\"Output 250 MAE: {results[5]:.4f}\")\n",
    "print(f\"Output 100 MSE: {results[6]:.4f}\")\n",
    "print(f\"Output 100 R^2: {results[7]:.4f}\")\n",
    "print(f\"Output 100 MAE: {results[8]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5203ab-c364-488b-82c6-b0d49fab45cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the weight of the trained network\n",
    "model.save_weights(\"/home/jovyan/private/thesis_data/code/final_code/weight/0403_3_2e-3_25.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece171f-67a4-4412-a2ab-534935e2dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_biomass_estimation(image, regression_model, patch_size, step=！！！):\n",
    "    original_height, original_width, _ = image.shape\n",
    "    padded, (pad_height, pad_width) = pad_image_to_patch_size(image, patch_size)\n",
    "    height, width, _ = padded.shape\n",
    "    \n",
    "    predictions = np.zeros((height, width))  # 单通道预测值\n",
    "    \n",
    "    row = 0\n",
    "    while row + patch_size <= height:\n",
    "        row_patches = []\n",
    "\n",
    "        col = 0 \n",
    "        while col + patch_size <= width:\n",
    "            patch = padded[row:row + patch_size, col:col + patch_size, :]\n",
    "            row_patches.append(patch)\n",
    "            col += step\n",
    "\n",
    "        batch = np.array(row_patches)\n",
    "        row_predictions = regression_model.predict(batch, verbose=0)\n",
    "\n",
    "        col, patch_idx = 0, 0\n",
    "        while col + patch_size <= width:\n",
    "            # 对于回归，我们可能直接取预测值而不是累加\n",
    "            predictions[row:row + patch_size, col:col + patch_size] = \\\n",
    "                row_predictions[patch_idx].reshape(patch_size, patch_size)\n",
    "            col += step\n",
    "            patch_idx += 1\n",
    "\n",
    "        row += step\n",
    "\n",
    "    predictions = predictions[\n",
    "        pad_height:pad_height + original_height,\n",
    "        pad_width:pad_width + original_width\n",
    "    ]\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9810690-f947-4d87-9904-df66928f497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENE_IDX = 0\n",
    "image_path = os.path.join(IMAGE_DIR, VAL_IMAGES[SCENE_IDX])\n",
    "label_path = os.path.join(LABEL_DIR, VAL_IMAGES[SCENE_IDX])\n",
    "\n",
    "image = read_image(image_path, normalise=True)\n",
    "label = map_classes(read_image(label_path))\n",
    "\n",
    "prediction = apply_segmentation_with_fcn(image, model)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(16, 7))\n",
    "\n",
    "axs[0].imshow(image[:, :, [2, 1, 0]])\n",
    "axs[0].set_title(\"Satellite image\")\n",
    "axs[1].imshow(label[:, :, 0])\n",
    "axs[1].set_title(\"Groundtruth\")\n",
    "axs[2].imshow(prediction)\n",
    "axs[2].set_title(\"U-Net prediction\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0c23b1-31e6-43b7-9a8f-b4cf7b7ede67",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENE_IDX = 1\n",
    "image_path = os.path.join(IMAGE_DIR, VAL_IMAGES[SCENE_IDX])\n",
    "label_path = os.path.join(LABEL_DIR, VAL_IMAGES[SCENE_IDX])\n",
    "\n",
    "image = read_image(image_path, normalise=True)\n",
    "label = map_classes(read_image(label_path))\n",
    "\n",
    "prediction = apply_segmentation_with_fcn(image, model)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(16, 7))\n",
    "\n",
    "axs[0].imshow(image[:, :, [2, 1, 0]])\n",
    "axs[0].set_title(\"Satellite image\")\n",
    "axs[1].imshow(label[:, :, 0])\n",
    "axs[1].set_title(\"Groundtruth\")\n",
    "axs[2].imshow(prediction)\n",
    "axs[2].set_title(\"U-Net prediction\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a9310-48fe-4955-a5c0-1a0ede1b06d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3269cdb-f739-424c-a981-0fd5c4ac7344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
