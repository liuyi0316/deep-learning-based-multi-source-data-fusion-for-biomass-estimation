{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e69879ea-c334-48be-81bb-71cc1c288762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cbf550a-ac6a-4af0-8df5-bae8c61ab70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e186a1b2-a1f9-460b-9782-86480dc98440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd4362a9-3b08-4cd5-b598-202d1069086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "276a8d4c-cfb1-4522-98fe-e3be71493cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.optimizers as optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cf52d0d-76f5-4169-a99f-15b203edb283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.utils as kutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "05f67543-fb74-4c10-9322-5caf602a4384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a448afae-8eca-4080-bd78-b0372099f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7a0d6d5-0552-4d2b-99e2-d66567e85aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7780987f-98ad-4ebd-9df2-e290724d999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5688abaa-fcf4-4127-bfd5-718ac927d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3725b710-b714-4e25-999c-512b0da7fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7b55d69b-7fb1-4504-ae64-1e83ee6ae2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf049ec9-5f02-4b68-a03c-c9acf90560ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "31b0bcc2-8d20-4790-8558-5e7e50330c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83e9b236-84a5-43ba-91be-bbf5c500680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import losses\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f0f2490f-869e-4508-a641-472fd9434a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fusion import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a5da5afb-9e0c-43f6-a076-618e6fc652ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import fusion  ######改成py！！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a81b1426-509b-4458-95f9-56d8395aca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####optical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2dcb841a-3b21-4616-b826-ed6c9334a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 定义数据集目录\n",
    "BASE_DIR = \"/home/jovyan/private/thesis_data/code/final_code/dataset\"\n",
    "# 假设您有三个不同的目录，分别存储不同类型的图像\n",
    "S1_IMAGE_DIR = os.path.join(BASE_DIR, \"sentinel1_images\")\n",
    "S2_10_IMAGE_DIR = os.path.join(BASE_DIR, \"sentinel2_10_images\")\n",
    "S2_20_IMAGE_DIR = os.path.join(BASE_DIR, \"sentinel2_20_images\")\n",
    "GEDI_IMAGE_DIR = os.path.join(BASE_DIR, \"gedi_4\")\n",
    "LABEL_250_DIR = os.path.join(BASE_DIR, \"LABEL_250_DIR\")\n",
    "LABEL_100_DIR = os.path.join(BASE_DIR, \"LABEL_100_DIR\")\n",
    "\n",
    "\n",
    "# 定义常量\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "EPOCHS = 1000\n",
    "STEPS = 500\n",
    "\n",
    "# 定义测试和验证图像的文件名\n",
    "# 假设每种类型的图像都有相同的命名方式\n",
    "TRAIN_IMAGES = [\"2.tif\", \"7.tif\", \"4.tif\", \"5.tif\", \"9.tif\"]\n",
    "VAL_IMAGES = [\"6.tif\", \"3.tif\"]\n",
    "TEST_IMAGES = [\"8.tif\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a31e4d1-3eab-4d46-8fc9-e6f3cf00a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_sizes = {\"s1\": (224, 224), \"s2_10\": (224, 224),\"s2_20\":(112,112), \"gedi\": (28, 28), \"LABEL_250_DIR\": (9, 9), \"LABEL_100_DIR\": (23, 23)}\n",
    "bands_count = {\"s1\": 6, \"s2_10\": 4,\"s2_20\":6,\"gedi\":4 }\n",
    "label_dirs = ['LABEL_250_DIR', 'LABEL_100_DIR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0361438-023f-49ab-90ba-62c9996176cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####read multiband image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1398537c-4a34-45aa-9499-f94d047e7096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess_image(image_path, normalise_percentiles=(0.5, 99), is_complex=False):\n",
    "    with rasterio.open(image_path) as image_file:\n",
    "        image_arr = image_file.read()  # 以[通道, 高度, 宽度]格式读取所有波段\n",
    "       \n",
    "        image_arr[image_arr == image_file.nodata] = np.nan\n",
    "                # 如果提供了模板，则应用模板\n",
    "        # if template is not None:\n",
    "        #     image_arr = apply_template(image_arr, template)\n",
    "        \n",
    "        if normalise_percentiles:\n",
    "            for band in range(image_arr.shape[0]):\n",
    "                band_arr = image_arr[band, :, :]\n",
    "                min_value = np.nanpercentile(band_arr, normalise_percentiles[0])\n",
    "                max_value = np.nanpercentile(band_arr, normalise_percentiles[1])\n",
    "                if max_value - min_value > np.finfo(float).eps:\n",
    "                    image_arr[band, :, :] = (band_arr - min_value) / (max_value - min_value)\n",
    "                else:\n",
    "                    image_arr[band, :, :] = np.zeros_like(band_arr)\n",
    "                    \n",
    "                    \n",
    "        if is_complex:\n",
    "            # 对于复数数据的特殊处理\n",
    "            real_channel_1 = np.expand_dims(image_arr[0], axis=0)  # 第一个通道，扩展维度以便堆叠\n",
    "            imag_channel_1 = np.zeros_like(real_channel_1)  # 第一个通道的虚部，使用零填充\n",
    "            \n",
    "            complex_real = np.expand_dims(image_arr[1], axis=0)  # 第二个通道作为复数的实部\n",
    "            complex_imag = np.expand_dims(image_arr[2], axis=0)  # 第三个通道作为复数的虚部\n",
    "            \n",
    "            real_channel_4 = np.expand_dims(image_arr[3], axis=0)  # 第四个通道\n",
    "            imag_channel_4 = np.zeros_like(real_channel_4)  # 第四个通道的虚部，使用零填充\n",
    "            \n",
    "            # 沿通道轴堆叠以创建6个通道\n",
    "            image_arr = np.concatenate([real_channel_1, imag_channel_1, complex_real, complex_imag, real_channel_4, imag_channel_4], axis=0)\n",
    "\n",
    "        # 在返回之前将 NaN 和 Inf 转换为 0\n",
    "        # 此处 posinf 和 neginf 参数可用于指定用于替换正、负无穷的值；默认行为是用最大或最小的浮点数替换\n",
    "        image_arr = np.nan_to_num(image_arr, nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "    return image_arr.transpose(1, 2, 0)  # 重新排序维度为高度 x 宽度 x 通道\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "41120f2c-d4e5-4211-bbe8-e1d215f8880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_single_band_image(image_path, normalise_percentiles=(0, 100)):\n",
    "    with rasterio.open(image_path) as image_file:\n",
    "        image_arr = image_file.read(1)  # Reads the first band\n",
    "        \n",
    "        # Checks and replaces nodata values with np.nan\n",
    "        if image_file.nodata is not None:\n",
    "            image_arr[image_arr == image_file.nodata] = np.nan\n",
    "        \n",
    "        # Applies normalization if needed\n",
    "        if normalise_percentiles:\n",
    "            min_value = np.nanpercentile(image_arr, normalise_percentiles[0])\n",
    "            max_value = np.nanpercentile(image_arr, normalise_percentiles[1])\n",
    "            if max_value - min_value > np.finfo(float).eps:\n",
    "                image_arr = (image_arr - min_value) / (max_value - min_value)\n",
    "            else:\n",
    "                image_arr = np.zeros_like(image_arr)\n",
    "        \n",
    "        # Converts np.nan to 0.0\n",
    "        single_band_image = np.nan_to_num(image_arr, nan=0.0)\n",
    "    \n",
    "    # Adds a channel dimension and returns\n",
    "    return np.expand_dims(single_band_image, axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b58aa231-15f6-4e9d-aafe-68338835f30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#反归一化：在某些情况下，特别是回归问题中，你可能需要将预测结果“反归一化”回原始的数值范围，以便结果更易于理解和使用。这要求保存归一化过程中使用的参数（如最小值和最大值），以便在预测后进行逆操作。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "79b1d849-272a-4131-96ab-7011035702cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####别忘了patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a504e62d-80ff-4e72-b0a4-3152510cb883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image_to_patch_size(image, patch_size):\n",
    "    height, width, depth = image.shape\n",
    "    patch_height, patch_width = patch_size  # 解包元组，分别获取补丁的高度和宽度\n",
    "\n",
    "    # 计算目标高度和宽度\n",
    "    target_height = patch_height * (height // patch_height + (1 if height % patch_height != 0 else 0))\n",
    "    target_width = patch_width * (width // patch_width + (1 if width % patch_width != 0 else 0))\n",
    "\n",
    "    # 计算填充量\n",
    "    pad_height = (target_height - height) // 2\n",
    "    pad_width = (target_width - width) // 2\n",
    "\n",
    "    # 创建填充后的图像\n",
    "    padded = np.zeros((target_height, target_width, depth), dtype=image.dtype)\n",
    "    padded[pad_height:pad_height + height, pad_width:pad_width + width, :] = image\n",
    "\n",
    "    return padded, (pad_height, pad_width)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7c5e9e41-3a55-43a2-adf5-28748da61a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainSequence(kutils.Sequence):\n",
    "    def __init__(self, filenames, batch_size, patch_sizes, bands_count, len, label_dirs):\n",
    "        self.filenames = filenames\n",
    "        self.batch_size = batch_size\n",
    "        self.patch_sizes = patch_sizes  # 字典，包含每种图像和标签的补丁大小\n",
    "        self.bands_count = bands_count  # 字典，包含每种图像类型的波段数\n",
    "        self.len = len\n",
    "        self.label_dirs = ['LABEL_250_DIR', 'LABEL_100_DIR']  # 列表，包含标签的目录\n",
    "        self.read_dataset()\n",
    "\n",
    "    def read_dataset(self):\n",
    "        self.data = []\n",
    "        for filename in self.filenames:\n",
    "            # 读取和处理图像\n",
    "            s1_image_path = os.path.join(S1_IMAGE_DIR, filename)\n",
    "            s2_10_image_path = os.path.join(S2_10_IMAGE_DIR, filename)\n",
    "            s2_20_image_path = os.path.join(S2_20_IMAGE_DIR, filename)\n",
    "            gedi_image_path = os.path.join(GEDI_IMAGE_DIR, filename)\n",
    "            \n",
    "            #s1_image = read_and_preprocess_image(s1_image_path, normalise=True)\n",
    "            s1_image = read_and_preprocess_image(s1_image_path, is_complex=True)\n",
    "\n",
    "            \n",
    "            s2_10_image = read_and_preprocess_image(s2_10_image_path)\n",
    "            s2_20_image = read_and_preprocess_image(s2_20_image_path)\n",
    "            gedi_image = read_and_preprocess_image(gedi_image_path)\n",
    "            \n",
    "            # Pad each image according to its patch size\n",
    "            s1_image, _ = pad_image_to_patch_size(s1_image, self.patch_sizes['s1'])\n",
    "            s2_10_image, _ = pad_image_to_patch_size(s2_10_image, self.patch_sizes['s2_10'])\n",
    "            s2_20_image, _ = pad_image_to_patch_size(s2_20_image, self.patch_sizes['s2_20'])\n",
    "            gedi_image, _ = pad_image_to_patch_size(gedi_image, self.patch_sizes['gedi'])\n",
    "\n",
    "\n",
    "            images = {'s1': s1_image, 's2_10': s2_10_image, 's2_20':s2_20_image, 'gedi': gedi_image}\n",
    "\n",
    "            # 读取和处理标签\n",
    "            labels = []\n",
    "            for label_type in self.label_dirs:\n",
    "                label_path = os.path.join(BASE_DIR, label_type, filename)\n",
    "                label = read_single_band_image(label_path)\n",
    "                # 使用 label_type 作为键来获取对应的补丁大小\n",
    "                label, _ = pad_image_to_patch_size(label, self.patch_sizes[label_type])\n",
    "                labels.append(label)\n",
    "\n",
    "\n",
    "            self.data.append((images, labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = {key: np.empty((self.batch_size, *self.patch_sizes[key], self.bands_count[key])) for key in ['s1', 's2_10', 's2_20', 'gedi']}\n",
    "        batch_y = [np.empty((self.batch_size, *self.patch_sizes[label_dir], 1)) for label_dir in self.label_dirs]\n",
    "\n",
    "        for patch_index in range(self.batch_size):\n",
    "            images, labels = self.sample_image()\n",
    "\n",
    "            # 基于参考图像（例如s1）计算采样起始点的比例\n",
    "            ref_image = images['s1']\n",
    "            y_ratio, x_ratio = self.calculate_sampling_start_point(ref_image, self.patch_sizes['s1'])\n",
    "\n",
    "            for key, image in images.items():\n",
    "                patch_size = self.patch_sizes[key]\n",
    "                batch_x[key][patch_index] = self.sample_patch(image, patch_size, y_ratio, x_ratio)\n",
    "\n",
    "            for i, label_dir in enumerate(self.label_dirs):\n",
    "                label = labels[i]\n",
    "                label_patch_size = self.patch_sizes[label_dir]\n",
    "                batch_y[i][patch_index] = self.sample_patch(label, label_patch_size, y_ratio, x_ratio)\n",
    "\n",
    "        return [batch_x[key] for key in batch_x], batch_y\n",
    "\n",
    "    def sample_image(self):\n",
    "        # 随机选择一个图像和标签集\n",
    "        image_index = np.random.choice(len(self.data))\n",
    "        selected_data = self.data[image_index]\n",
    "        images = selected_data[0]  # 第一个元素是图像的字典\n",
    "        labels = selected_data[1]  # 第二个元素是标签的列表\n",
    "        # 打印选中的image_index\n",
    "        #print(\"Selected image index:\", image_index)\n",
    "        return images, labels  # 返回图像字典和标签列表\n",
    "\n",
    "    def sample_patch(self, image, patch_size, y_ratio, x_ratio):\n",
    "        # 根据提供的比例和补丁大小采样补丁\n",
    "        height, width, _ = image.shape\n",
    "        y_start = int((height - patch_size[0]) * y_ratio)\n",
    "        x_start = int((width - patch_size[1]) * x_ratio)\n",
    "        return image[y_start:y_start + patch_size[0], x_start:x_start + patch_size[1], :]\n",
    "\n",
    "    def calculate_sampling_start_point(self, reference_image, reference_patch_size):\n",
    "        # 基于参考图像和参考补丁大小计算采样起始点的比例\n",
    "        height, width, _ = reference_image.shape\n",
    "        y_ratio = np.random.uniform(0, 1 - reference_patch_size[0] / height)\n",
    "        x_ratio = np.random.uniform(0, 1 - reference_patch_size[1] / width)\n",
    "        return y_ratio, x_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598367b1-13cf-4e20-88b8-9c83b9381d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = TrainSequence(TRAIN_IMAGES, BATCH_SIZE, patch_sizes, bands_count, STEPS, label_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a578c81e-e699-45b4-b6df-be480f694e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def check_nan_or_inf_in_batch(data):\n",
    "    #\"\"\"检查批次数据中是否包含NaN或Inf值。\"\"\"\n",
    "    if isinstance(data, dict):\n",
    "        # 如果数据是字典类型，则遍历每个键\n",
    "        for key, value in data.items():\n",
    "            if np.any(np.isnan(value)) or np.any(np.isinf(value)):\n",
    "                return True\n",
    "    elif isinstance(data, list):\n",
    "        # 如果数据是列表\n",
    "        for item in data:\n",
    "            if isinstance(item, np.ndarray):\n",
    "                if np.any(np.isnan(item)) or np.any(np.isinf(item)):\n",
    "                    return True\n",
    "            else:\n",
    "                # 对于嵌套的列表或其它结构，需要进一步检查或适当处理\n",
    "                pass\n",
    "    elif isinstance(data, np.ndarray):\n",
    "        # 对于直接的NumPy数组\n",
    "        if np.any(np.isnan(data)) or np.any(np.isinf(data)):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "# 假设 train_sequence 是你的 TrainSequence 实例\n",
    "for idx in range(len(train_sequence)):\n",
    "    batch_x, batch_y = train_sequence[idx]  # 获取批次数据\n",
    "    \n",
    "    # 检查特征数据和标签数据中是否有 NaN 或 Inf 值\n",
    "    if check_nan_or_inf_in_batch(batch_x):\n",
    "        print(f\"NaN or Inf detected in features of batch {idx}\")\n",
    "    if check_nan_or_inf_in_batch(batch_y):\n",
    "        print(f\"NaN or Inf detected in labels of batch {idx}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba09e345-3443-410a-95af-ca1b0e43dcdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_sequence[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb8514d-4a90-4353-9391-213269341d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_sequence[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ca4c888-017e-4b1a-9587-4d3373341cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = train_sequence[8] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ead641-98bd-47ee-83f1-f13fe63990f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对 x 进行检查，这里假设 x 是一个列表或数组的列表\n",
    "for i, item in enumerate(x):\n",
    "    if np.isnan(item).any():\n",
    "        print(f\"NaN value detected in x at index {i}\")\n",
    "\n",
    "# 对 y 进行检查，这里假设 y 是一个列表或数组的列表\n",
    "for i, item in enumerate(y):\n",
    "    if np.isnan(item).any():\n",
    "        print(f\"NaN value detected in y at index {i}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1155dc11-8334-483c-bd5c-f1cceb9796b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打印x的类型和内容示例\n",
    "print(type(y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82557aab-bf8b-4bdc-aa92-c42c115518b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# x 是一个列表，y 是一个标签列表的列表\n",
    "# 假设x中的顺序与bands_count中的键顺序一致\n",
    "\n",
    "# 计算绘图的总行数：所有输入的波段数 + 所有输出的数量\n",
    "input_band_count = sum(bands_count.values())\n",
    "output_label_count = sum(len(labels) for labels in y)\n",
    "nrows = input_band_count + output_label_count\n",
    "ncols = 1  # 因为我们只查看第一个批次的数据\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(5, nrows * 2), squeeze=False)\n",
    "\n",
    "current_row = 0\n",
    "# 可视化每个输入图像的所有波段\n",
    "for input_index, (input_key, band_count) in enumerate(bands_count.items()):\n",
    "    for band_index in range(band_count):\n",
    "        ax = axes[current_row, 0]\n",
    "        ax.imshow(x[input_index][0, :, :, band_index], cmap='gray')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'Input: {input_key}, Band: {band_index + 1}')\n",
    "        current_row += 1\n",
    "\n",
    "# 可视化每个输出标签\n",
    "for label_set_index, label_set in enumerate(y):  # y 是标签列表的列表\n",
    "    for label_index, label_data in enumerate(label_set):\n",
    "        ax = axes[current_row, 0]\n",
    "        ax.imshow(label_data[:, :, 0], cmap='viridis')  # 这里做了修正\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'Output Label Set: {label_set_index + 1}, Label: {label_index + 1}')\n",
    "        current_row += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77248a4b-9b35-4f67-b91e-da743ee5c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import os\n",
    "# import keras.utils as kutils\n",
    "\n",
    "# class ValSequence(kutils.Sequence):\n",
    "#     def __init__(self, filenames, batch_size, patch_sizes, bands_count, label_dirs):\n",
    "#         self.filenames = filenames\n",
    "#         self.batch_size = batch_size\n",
    "#         self.patch_sizes = patch_sizes\n",
    "#         self.bands_count = bands_count\n",
    "#         self.label_dirs = label_dirs\n",
    "#         self.read_dataset()\n",
    "#         self.reset()\n",
    "\n",
    "#     def read_dataset(self):\n",
    "#         self.data = []\n",
    "#         min_patches_count = None\n",
    "\n",
    "#         for filename in self.filenames:\n",
    "#             # 读取和处理图像\n",
    "#             s1_image_path = os.path.join(S1_IMAGE_DIR, filename)\n",
    "#             s2_10_image_path = os.path.join(S2_10_IMAGE_DIR, filename)\n",
    "#             s2_20_image_path = os.path.join(S2_20_IMAGE_DIR, filename)\n",
    "#             gedi_image_path = os.path.join(GEDI_IMAGE_DIR, filename)\n",
    "            \n",
    "#             #s1_image = read_and_preprocess_image(s1_image_path, normalise=True)\n",
    "#             s1_image = read_and_preprocess_image(s1_image_path, is_complex=True)\n",
    "\n",
    "#             # 然后处理其他图像，并使用S1图像作为模板\n",
    "#             s2_10_image = read_and_preprocess_image(s2_10_image_path)\n",
    "#             s2_20_image = read_and_preprocess_image(s2_20_image_path)\n",
    "#             gedi_image = read_and_preprocess_image(gedi_image_path)\n",
    "            \n",
    "#             images = {'s1': s1_image, 's2_10': s2_10_image, 's2_20':s2_20_image, 'gedi': gedi_image}\n",
    "\n",
    "#             labels = {}\n",
    "#             for label_type in self.label_dirs:\n",
    "#                 label_path = os.path.join(BASE_DIR, label_type, filename)\n",
    "#                 label = read_single_band_image(label_path)\n",
    "#                 labels[label_type] = label\n",
    "\n",
    "\n",
    "#             # Pad images and labels to their respective patch sizes\n",
    "#             for key in images:\n",
    "#                 images[key], _ = pad_image_to_patch_size(images[key], self.patch_sizes[key])\n",
    "#             for key in labels:\n",
    "#                 labels[key], _ = pad_image_to_patch_size(labels[key], self.patch_sizes[key])\n",
    "\n",
    "#             # Calculate patches count for each image and label, then update min_patches_count\n",
    "#             all_sizes = {**images, **labels}  # Combine images and labels for unified processing\n",
    "#             for key, item in all_sizes.items():\n",
    "#                 patch_size = self.patch_sizes[key]\n",
    "#                 patches_count = (item.shape[0] // patch_size[0]) * (item.shape[1] // patch_size[1])\n",
    "#                 if min_patches_count is None or patches_count < min_patches_count:\n",
    "#                     min_patches_count = patches_count\n",
    "\n",
    "#             self.data.append((images, labels))\n",
    "\n",
    "#         self.len = min_patches_count * len(self.filenames) // self.batch_size\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return self.len\n",
    "    \n",
    "    \n",
    "#     def __getitem__(self, idx):\n",
    "#         batch_x = {key: np.empty((self.batch_size, *self.patch_sizes[key], self.bands_count[key])) for key in ['s1', 's2_10', 's2_20', 'gedi']}\n",
    "#         batch_y = {key: np.empty((self.batch_size, *self.patch_sizes[key], 1)) for key in self.label_dirs}\n",
    "\n",
    "#         # 为整个batch计算一个统一的采样起始点\n",
    "#         images, labels = self.data[idx % len(self.data)]\n",
    "#         ref_image = list(images.values())[0]  # 使用第一个图像作为参考\n",
    "#         patch_size = list(self.patch_sizes.values())[0]  # 使用第一个patch size作为参考\n",
    "#         height, width, _ = ref_image.shape\n",
    "#         max_y = height - patch_size[0]\n",
    "#         max_x = width - patch_size[1]\n",
    "#         y = np.random.randint(0, max_y) if max_y > 0 else 0\n",
    "#         x = np.random.randint(0, max_x) if max_x > 0 else 0\n",
    "\n",
    "#         for i in range(self.batch_size):\n",
    "#             for key, image in images.items():\n",
    "#                 batch_x[key][i, ...] = image[y:y + self.patch_sizes[key][0], x:x + self.patch_sizes[key][1], :]\n",
    "#             for key, label in labels.items():\n",
    "#                 batch_y[key][i, ...] = label[y:y + self.patch_sizes[key][0], x:x + self.patch_sizes[key][1], :]\n",
    "\n",
    "#         return [batch_x[key] for key in batch_x], [batch_y[key] for key in batch_y]\n",
    "\n",
    "\n",
    "#     def sample_image(self):\n",
    "#         image_index = np.random.choice(len(self.data))\n",
    "#         return self.data[image_index]\n",
    "\n",
    "#     def reset(self):\n",
    "#         # Resets the sequence to the start\n",
    "#         self.image_index = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4fb6a1-f4e9-4a03-82f5-0a3199f49b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sequence =TrainSequence(VAL_IMAGES,BATCH_SIZE, patch_sizes, bands_count, STEPS, label_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9a3a37-874a-4ac7-8663-ba4b459339ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 假设 train_sequence 是你的 TrainSequence 实例\n",
    "for idx in range(len(val_sequence)):\n",
    "    batch_x, batch_y = val_sequence[idx]  # 获取批次数据\n",
    "    \n",
    "    # 检查特征数据和标签数据中是否有 NaN 或 Inf 值\n",
    "    if check_nan_or_inf_in_batch(batch_x):\n",
    "        print(f\"NaN or Inf detected in features of batch {idx}\")\n",
    "    if check_nan_or_inf_in_batch(batch_y):\n",
    "        print(f\"NaN or Inf detected in labels of batch {idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa0b135-9bcd-40df-924d-7163186f0fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x,y=val_sequence[1]\n",
    "# x 是一个列表，y 是一个标签列表的列表\n",
    "# 假设x中的顺序与bands_count中的键顺序一致\n",
    "\n",
    "# 计算绘图的总行数：所有输入的波段数 + 所有输出的数量\n",
    "input_band_count = sum(bands_count.values())\n",
    "output_label_count = sum(len(labels) for labels in y)\n",
    "nrows = input_band_count + output_label_count\n",
    "ncols = 1  # 因为我们只查看第一个批次的数据\n",
    "\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=(5, nrows * 2), squeeze=False)\n",
    "\n",
    "current_row = 0\n",
    "# 可视化每个输入图像的所有波段\n",
    "for input_index, (input_key, band_count) in enumerate(bands_count.items()):\n",
    "    for band_index in range(band_count):\n",
    "        ax = axes[current_row, 0]\n",
    "        ax.imshow(x[input_index][0, :, :, band_index], cmap='gray')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'Input: {input_key}, Band: {band_index + 1}')\n",
    "        current_row += 1\n",
    "\n",
    "# 可视化每个输出标签\n",
    "for label_set_index, label_set in enumerate(y):  # y 是标签列表的列表\n",
    "    for label_index, label_data in enumerate(label_set):\n",
    "        ax = axes[current_row, 0]\n",
    "        ax.imshow(label_data[:, :, 0], cmap='viridis')  # 这里做了修正\n",
    "        ax.axis('off')\n",
    "        ax.set_title(f'Output Label Set: {label_set_index + 1}, Label: {label_index + 1}')\n",
    "        current_row += 1\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31fe476-c3fa-4398-82fd-838e2ae0b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_sequence = ValSequence(VAL_IMAGES, BATCH_SIZE, patch_sizes, bands_count, label_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ead7d-82df-43cf-8558-fc64f4e8d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置输入尺寸\n",
    "input_shape_s1 = 224,224,6  # Sentinel-1 输入尺寸\n",
    "input_shape_s10 = 224,224,4  # Sentinel-2 输入尺寸\n",
    "input_shape_s20 = 112,112,6  # Sentinel-2 输入尺寸\n",
    "input_shape_gedi = 28, 28, 4  # GEDI 输入尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6db440-af6d-459b-b694-97dfb21cea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(input_shape_s1, input_shape_s10, input_shape_s20, input_shape_gedi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45cb51-0879-4461-a924-8640a28d0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48c7539d-632b-4940-847a-7d2719236548",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "# 自定义损失函数\n",
    "def custom_mse(y_true, y_pred):\n",
    "    eps = K.epsilon()  # 获取一个小常数\n",
    "    return K.mean(K.square(y_pred - y_true) + eps, axis=-1)  # 将小常数加到损失计算中\n",
    "\n",
    "# 定义损失函数字典，使用自定义损失函数\n",
    "losses1 = {\n",
    "    'output_250': custom_mse,  # 使用自定义的损失函数\n",
    "    'output_100': custom_mse   # 同上\n",
    "}\n",
    "\n",
    "# 损失权重保持不变\n",
    "loss_weights1 = {\n",
    "    'output_250': 0.4,\n",
    "    'output_100': 0.6\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8d7ce7cd-e7b1-46e9-be43-26b9b2eca278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# losses1 = {\n",
    "#     'output_250': 'mean_squared_error',  # 假设这是正确的层名称\n",
    "#     'output_100': 'mean_squared_error'   # 确保这里没有多余的空格\n",
    "# }\n",
    "# loss_weights1 = {\n",
    "#     'output_250': 0.7,\n",
    "#     'output_100': 0.3\n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "80e7e7d3-259c-436e-94c9-1e39479b9363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "2600c8bc-5b91-455b-aaf9-57efd4206c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义 R² 指标函数\n",
    "def r_squared(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a4d83790-bcc6-4fee-9d6b-129c56e02ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = keras.optimizers.Adam(1e-5, clipnorm=1, epsilon=1e-4)\n",
    "model.compile(optimizer=optimizer1, loss=losses1, loss_weights=loss_weights1, metrics=['mse',r_squared,'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8471e586-f422-4f58-ada1-3a1f071674d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "582dd10a-42cd-4b73-be7f-d69c39303028",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "\n",
    "class DetectNaNCallback(Callback):\n",
    "    def on_batch_end(self, batch, logs=None):\n",
    "        weights = self.model.get_weights()\n",
    "        if any(np.isnan(w).any() for w in weights):\n",
    "            print(f'NaN detected in weights at batch {batch}')\n",
    "            self.model.stop_training = True\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        weights = self.model.get_weights()\n",
    "        if any(np.isnan(w).any() for w in weights):\n",
    "            print(f'NaN detected in weights at epoch {epoch}')\n",
    "            self.model.stop_training = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9f8f70d2-3445-4791-8f47-93c6f40ac581",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_detect_callback = DetectNaNCallback()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "882064df-5071-459a-b732-556f03944aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 定义早停规则\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # 监控的指标，常见的有'val_loss'和'val_accuracy'\n",
    "    min_delta=0.001,  # 表示被监控指标的最小变化量，只有大于这个值时才认为模型有改善\n",
    "    patience=10,  # 指定在监控指标没有改善的情况下等待的epochs数量\n",
    "    verbose=1,  # 控制输出，1表示输出早停信息\n",
    "    mode='min',  # 在监控指标为'val_loss'时，我们希望其最小化，因此设置为'min'。如果监控指标为'val_accuracy'，则设置为'max'\n",
    "    restore_best_weights=True  # 当早停发生时，是否恢复到最好的模型权重\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf465795-5d86-4a4c-b962-492807fbfc68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "500/500 [==============================] - 607s 1s/step - loss: 0.0280 - output_250_loss: 0.0286 - output_100_loss: 0.0276 - output_250_mse: 0.0286 - output_250_r_squared: -140271.9062 - output_250_mae: 0.1233 - output_100_mse: 0.0276 - output_100_r_squared: -1182069.1250 - output_100_mae: 0.1217 - val_loss: 0.0912 - val_output_250_loss: 0.0958 - val_output_100_loss: 0.0881 - val_output_250_mse: 0.0958 - val_output_250_r_squared: -16911350.0000 - val_output_250_mae: 0.2506 - val_output_100_mse: 0.0881 - val_output_100_r_squared: -108966856.0000 - val_output_100_mae: 0.2366\n",
      "Epoch 2/1000\n",
      "301/500 [=================>............] - ETA: 3:10 - loss: 0.0280 - output_250_loss: 0.0286 - output_100_loss: 0.0276 - output_250_mse: 0.0286 - output_250_r_squared: -21549.3965 - output_250_mae: 0.1228 - output_100_mse: 0.0276 - output_100_r_squared: -82930.1094 - output_100_mae: 0.1215"
     ]
    }
   ],
   "source": [
    "history= model.fit(\n",
    "    train_sequence, \n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=1, \n",
    "    validation_data=val_sequence,\n",
    "    callbacks=[nan_detect_callback,early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e975439d-e6c8-4e3c-8a7d-835b09527865",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [56], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# 绘制损失曲线\u001b[39;00m\n\u001b[1;32m      5\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSample net training curve loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrain Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m], label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Loss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m axs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mlegend()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot model training history\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n",
    "\n",
    "# 绘制损失曲线\n",
    "axs[0].set_title(\"Sample net training curve loss\")\n",
    "axs[0].plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "axs[0].plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "axs[0].legend()\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "\n",
    "# 绘制 MSE 曲线\n",
    "axs[1].set_title(\"Sample net training curve MSE\")\n",
    "axs[1].plot(history.history[\"mse\"], label=\"Train MSE\")\n",
    "axs[1].plot(history.history[\"val_mse\"], label=\"Validation MSE\")\n",
    "axs[1].legend()\n",
    "axs[1].set_ylabel(\"MSE\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65be8bf-2d09-4e02-b250-ab39e14770d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sequence.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6865df81-af9c-4711-9e21-ee6852bdacc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequence = ValSequence(TEST_IMAGES, BATCH_SIZE, patch_sizes, bands_count, ['LABEL_250_DIR', 'LABEL_100_DIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13887a3-327e-484c-8314-91fdd96ac7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mse = model.evaluate(test_sequence, verbose=0)\n",
    "print(f\"\\nTest loss: {loss:.4f}\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5203ab-c364-488b-82c6-b0d49fab45cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the weight of the trained network\n",
    "model.save_weights(\"unet_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece171f-67a4-4412-a2ab-534935e2dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_biomass_estimation(image, regression_model, patch_size, step=！！！):\n",
    "    original_height, original_width, _ = image.shape\n",
    "    padded, (pad_height, pad_width) = pad_image_to_patch_size(image, patch_size)\n",
    "    height, width, _ = padded.shape\n",
    "    \n",
    "    predictions = np.zeros((height, width))  # 单通道预测值\n",
    "    \n",
    "    row = 0\n",
    "    while row + patch_size <= height:\n",
    "        row_patches = []\n",
    "\n",
    "        col = 0 \n",
    "        while col + patch_size <= width:\n",
    "            patch = padded[row:row + patch_size, col:col + patch_size, :]\n",
    "            row_patches.append(patch)\n",
    "            col += step\n",
    "\n",
    "        batch = np.array(row_patches)\n",
    "        row_predictions = regression_model.predict(batch, verbose=0)\n",
    "\n",
    "        col, patch_idx = 0, 0\n",
    "        while col + patch_size <= width:\n",
    "            # 对于回归，我们可能直接取预测值而不是累加\n",
    "            predictions[row:row + patch_size, col:col + patch_size] = \\\n",
    "                row_predictions[patch_idx].reshape(patch_size, patch_size)\n",
    "            col += step\n",
    "            patch_idx += 1\n",
    "\n",
    "        row += step\n",
    "\n",
    "    predictions = predictions[\n",
    "        pad_height:pad_height + original_height,\n",
    "        pad_width:pad_width + original_width\n",
    "    ]\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9810690-f947-4d87-9904-df66928f497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENE_IDX = 0\n",
    "image_path = os.path.join(IMAGE_DIR, VAL_IMAGES[SCENE_IDX])\n",
    "label_path = os.path.join(LABEL_DIR, VAL_IMAGES[SCENE_IDX])\n",
    "\n",
    "image = read_image(image_path, normalise=True)\n",
    "label = map_classes(read_image(label_path))\n",
    "\n",
    "prediction = apply_segmentation_with_fcn(image, model)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(16, 7))\n",
    "\n",
    "axs[0].imshow(image[:, :, [2, 1, 0]])\n",
    "axs[0].set_title(\"Satellite image\")\n",
    "axs[1].imshow(label[:, :, 0])\n",
    "axs[1].set_title(\"Groundtruth\")\n",
    "axs[2].imshow(prediction)\n",
    "axs[2].set_title(\"U-Net prediction\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0c23b1-31e6-43b7-9a8f-b4cf7b7ede67",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENE_IDX = 1\n",
    "image_path = os.path.join(IMAGE_DIR, VAL_IMAGES[SCENE_IDX])\n",
    "label_path = os.path.join(LABEL_DIR, VAL_IMAGES[SCENE_IDX])\n",
    "\n",
    "image = read_image(image_path, normalise=True)\n",
    "label = map_classes(read_image(label_path))\n",
    "\n",
    "prediction = apply_segmentation_with_fcn(image, model)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(16, 7))\n",
    "\n",
    "axs[0].imshow(image[:, :, [2, 1, 0]])\n",
    "axs[0].set_title(\"Satellite image\")\n",
    "axs[1].imshow(label[:, :, 0])\n",
    "axs[1].set_title(\"Groundtruth\")\n",
    "axs[2].imshow(prediction)\n",
    "axs[2].set_title(\"U-Net prediction\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a9310-48fe-4955-a5c0-1a0ede1b06d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3269cdb-f739-424c-a981-0fd5c4ac7344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
