{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7770503e-1773-499b-ad05-6bf9cc94c123",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def setup_gpu_memory_growth():\n",
    "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        try:\n",
    "            for gpu in gpus:\n",
    "                tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        except RuntimeError as e:\n",
    "            # 打印异常信息\n",
    "            print(e)\n",
    "\n",
    "# 在程序的开始调用这个函数\n",
    "setup_gpu_memory_growth()\n",
    "\n",
    "# 以下是你的其他TensorFlow代码\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c97de78-cfda-4bc7-9da4-30fe33b9bbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 设置环境变量\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69879ea-c334-48be-81bb-71cc1c288762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbf550a-ac6a-4af0-8df5-bae8c61ab70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e186a1b2-a1f9-460b-9782-86480dc98440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4362a9-3b08-4cd5-b598-202d1069086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276a8d4c-cfb1-4522-98fe-e3be71493cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.optimizers as optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf52d0d-76f5-4169-a99f-15b203edb283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.utils as kutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f67543-fb74-4c10-9322-5caf602a4384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a448afae-8eca-4080-bd78-b0372099f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a0d6d5-0552-4d2b-99e2-d66567e85aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7780987f-98ad-4ebd-9df2-e290724d999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5688abaa-fcf4-4127-bfd5-718ac927d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3725b710-b714-4e25-999c-512b0da7fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf049ec9-5f02-4b68-a03c-c9acf90560ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e9b236-84a5-43ba-91be-bbf5c500680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import losses\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f2490f-869e-4508-a641-472fd9434a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fusion_224 import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcb841a-3b21-4616-b826-ed6c9334a9aa",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 定义数据集目录\n",
    "BASE_DIR = \"/home/jovyan/private/thesis_data/code/final_code/dataset\"\n",
    "# 假设您有三个不同的目录，分别存储不同类型的图像\n",
    "\n",
    "S1_IMAGE_DIR = os.path.join(BASE_DIR, \"sentinel1_10\")\n",
    "S2_10_IMAGE_DIR = os.path.join(BASE_DIR, \"sentinel2_10\")\n",
    "S2_20_IMAGE_DIR = os.path.join(BASE_DIR, \"sentinel2_20_images_normalized\")\n",
    "GEDI_IMAGE_DIR = os.path.join(BASE_DIR, \"gedi_2016\")\n",
    "LABEL_250_DIR = os.path.join(BASE_DIR, \"LABEL_250_DIR\")\n",
    "\n",
    "label_dirs = ['LABEL_250_DIR']\n",
    "\n",
    "\n",
    "BATCH_SIZE = 14\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353b76d3-7751-461c-aa02-87839563923e",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_IMAGES = ['9_3.tif', '27_2.tif','11_5.tif', '25_7.tif','18_3.tif', '21_6.tif',  '17_5.tif',  '7_3.tif', '4_3.tif', \n",
    "                '12_1.tif', '15_8.tif', '15_9.tif', '10_4.tif', '21_3.tif', '6_6.tif', '11_3.tif', '19_6.tif', '17_3.tif', \n",
    "                '2_1.tif', '18_5.tif', '24_2.tif','9_2.tif', '21_1.tif', '19_7.tif', '19_3.tif', '20_7.tif', '7_2.tif', '27_4.tif',\n",
    "                '18_6.tif', '2_5.tif', '20_8.tif','25_1.tif', '16_3.tif','24_8.tif', '22_2.tif', '2_3.tif', '4_2.tif', '12_2.tif', '10_3.tif', \n",
    "                '4_6.tif', '9_5.tif',  '18_4.tif', '15_6.tif', '22_6.tif','24_6.tif', '17_7.tif', '7_5.tif', '4_4.tif', \n",
    "                '10_5.tif', '9_1.tif', '20_5.tif', '17_4.tif', '19_1.tif', '6_2.tif', '22_5.tif', '7_1.tif', '27_6.tif','27_5.tif',\n",
    "                '6_3.tif', '16_2.tif', '18_2.tif', '6_5.tif','25_3.tif', '16_5.tif', '11_1.tif', '2_2.tif', '16_4.tif', '7_4.tif', '27_8.tif',\n",
    "                '19_2.tif','25_5.tif', '17_6.tif', '21_2.tif','24_4.tif', '4_5.tif', '9_4.tif', '20_9.tif', '20_6.tif', '2_4.tif', '22_1.tif', \n",
    "                '15_5.tif','25_9.tif', '11_2.tif', '10_6.tif', '21_7.tif', '12_7.tif', '11_4.tif','24_1.tif']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba71f3e-d491-4771-834e-6e980898f628",
   "metadata": {},
   "outputs": [],
   "source": [
    "VAL_IMAGES = ['18_9.tif','27_3.tif', '7_7.tif', '20_3.tif', '18_7.tif', '2_8.tif', '4_8.tif', '18_8.tif', \n",
    "              '12_5.tif', '20_1.tif', '19_4.tif', '17_8.tif','24_3.tif', '21_8.tif', '17_2.tif', '9_6.tif', \n",
    "              '9_8.tif', '17_1.tif', '19_5.tif','25_2.tif', '4_7.tif', '10_2.tif',  '16_8.tif', '25_4.tif',\n",
    "              '21_9.tif', '24_9.tif','22_3.tif', '11_8.tif', '10_8.tif', '2_6.tif', '19_8.tif', '6_8.tif', \n",
    "              '21_5.tif', '7_8.tif', '20_2.tif', '10_9.tif', '25_8.tif','12_4.tif', '12_8.tif', '4_9.tif', \n",
    "              '9_7.tif','27_7.tif',  '7_6.tif', '16_7.tif','24_7.tif', '15_4.tif', '11_9.tif', '16_6.tif', \n",
    "              '2_7.tif', '22_8.tif', '11_7.tif', '27_1.tif']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e41823-ffdd-45ae-b755-d9216a7f8c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_IMAGES = ['9_9.tif', '3_7.tif', '17_9.tif', '8_8.tif', '15_1.tif', '18_1.tif', '2_9.tif', '8_5.tif', '3_9.tif', \n",
    "               '21_4.tif', '7_9.tif', '4_1.tif', '3_3.tif', '3_6.tif', '3_5.tif', '3_2.tif', '6_9.tif', '11_6.tif', \n",
    "               '8_2.tif', '8_3.tif', '8_4.tif', '3_8.tif', '8_6.tif', '8_9.tif', '3_1.tif', '20_4.tif', '22_9.tif', \n",
    "               '8_7.tif', '3_4.tif', '8_1.tif', '10_1.tif', '16_9.tif', '19_9.tif','24_5.tif','25_6.tif','27_9.tif']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a31e4d1-3eab-4d46-8fc9-e6f3cf00a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_sizes = {\"s1\": (224, 224), \"s2_10\": (224, 224),\"s2_20\":(112,112), \"gedi\": (28, 28), \"LABEL_250_DIR\": (9, 9)}\n",
    "bands_count = {\"s1\": 6, \"s2_10\": 4,\"s2_20\":6,\"gedi\":101 }\n",
    "\n",
    "image_dirs = {\"s1\":S1_IMAGE_DIR,\"s2_10\":S2_10_IMAGE_DIR,\"s2_20\":S2_20_IMAGE_DIR, \"gedi\":GEDI_IMAGE_DIR }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eef455b-7953-42fc-84a6-cd9cbd7b9a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "import numpy as np\n",
    "\n",
    "def read_and_preprocess_image(image_path, normalise_percentiles=(1, 99), is_complex=False):\n",
    "    with rasterio.open(image_path) as image_file:\n",
    "        image_arr = image_file.read()  # 读取所有波段，以[通道, 高度, 宽度]的格式\n",
    "        \n",
    "        # 替换nodata和异常值为np.nan\n",
    "        if image_file.nodata is not None:\n",
    "            image_arr = np.where(image_arr == image_file.nodata, np.nan, image_arr)\n",
    "        \n",
    "        # 处理可能的极端负值\n",
    "        image_arr = np.where(\n",
    "            (image_arr == -1.7976931348623157e+308) | (image_arr == -3.4028234663852886e+38),\n",
    "            np.nan,\n",
    "            image_arr\n",
    "        )\n",
    "        \n",
    "        # 归一化\n",
    "        if normalise_percentiles:\n",
    "            for band in range(image_arr.shape[0]):\n",
    "                band_arr = image_arr[band, :, :]\n",
    "                min_val = np.nanpercentile(band_arr, normalise_percentiles[0])\n",
    "                max_val = np.nanpercentile(band_arr, normalise_percentiles[1])\n",
    "\n",
    "                if max_val - min_val > np.finfo(float).eps:\n",
    "                    norm_band = (band_arr - min_val) / (max_val - min_val)\n",
    "                    norm_band = np.clip(norm_band, 0, 1)  # 确保范围在0到1之间\n",
    "                    image_arr[band, :, :] = norm_band\n",
    "                else:\n",
    "                    image_arr[band, :, :] = np.zeros_like(band_arr)\n",
    "\n",
    "        if is_complex:  # 对于复数数据的特殊处理\n",
    "            # 第一个和第二个通道为复数的实部和虚部\n",
    "            complex_real = np.expand_dims(image_arr[0], axis=0)  # 第一个通道作为复数的实部\n",
    "            complex_imag = np.expand_dims(image_arr[1], axis=0)  # 第二个通道作为复数的虚部\n",
    "            \n",
    "            # 第三个和第四个通道\n",
    "            real_channel_1 = np.expand_dims(image_arr[2], axis=0)  # 第三个通道，扩展维度以便堆叠\n",
    "            imag_channel_1 = np.zeros_like(real_channel_1)  # 第三个通道的虚部，使用零填充\n",
    "            \n",
    "            real_channel_4 = np.expand_dims(image_arr[3], axis=0)  # 第四个通道\n",
    "            imag_channel_4 = np.zeros_like(real_channel_4)  # 第四个通道的虚部，使用零填充\n",
    "\n",
    "            # 沿通道轴堆叠以创建6个通道\n",
    "            image_arr = np.concatenate([complex_real, complex_imag, real_channel_1, imag_channel_1, real_channel_4, imag_channel_4], axis=0)\n",
    "\n",
    "        # 转换NaN为0，并处理无穷大的值\n",
    "        image_arr = np.nan_to_num(image_arr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "        # 重新排序维度为[高度, 宽度, 通道]\n",
    "        return image_arr.transpose(1, 2, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19616c3-b2fa-44fa-9435-865b36c533fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "def read_single_band_image(image_path):\n",
    "    with rasterio.open(image_path) as image_file:\n",
    "        image_arr = image_file.read(1)  # Read the first band\n",
    "\n",
    "        # Replace nodata values with np.nan\n",
    "        if image_file.nodata is not None:\n",
    "            image_arr[image_arr == image_file.nodata] = np.nan\n",
    "        \n",
    "        # Replace possible extreme values with np.nan\n",
    "        image_arr = np.where(\n",
    "            (image_arr == -1.7976931348623157e+308) | (image_arr == -3.4028234663852886e+38),\n",
    "            np.nan,\n",
    "            image_arr\n",
    "        )\n",
    "        \n",
    "        # Convert np.nan to 0\n",
    "        single_band_image = np.nan_to_num(image_arr, nan=0.0)\n",
    "\n",
    "    # Add a channel dimension and return\n",
    "    return np.expand_dims(single_band_image, axis=-1)  # Dimensions (height, width, 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4ead4e-b466-4da1-b253-0ab30b4618f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image_to_patch_size(image, patch_size):\n",
    "    height, width, depth = image.shape\n",
    "    patch_height, patch_width = patch_size\n",
    "\n",
    "    # 目标高度和宽度\n",
    "    target_height = patch_height * (height // patch_height + (1 if height % patch_height != 0 else 0))\n",
    "    target_width = patch_width * (width // patch_width + (1 if width % patch_width != 0 else 0))\n",
    "\n",
    "    # 计算填充量\n",
    "    pad_height = (target_height - height) // 2\n",
    "    pad_width = (target_width - width) // 2\n",
    "\n",
    "    # 创建填充后的图像\n",
    "    padded = np.zeros((target_height, target_width, depth), dtype=image.dtype)\n",
    "    padded[pad_height:pad_height + height, pad_width:pad_width + width, :] = image\n",
    "\n",
    "    padding_info = {\n",
    "        'padded_height': target_height,\n",
    "        'padded_width': target_width,\n",
    "        'top_pad': pad_height,\n",
    "        'left_pad': pad_width\n",
    "    }\n",
    "\n",
    "    return padded, padding_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c36e63-705a-40e0-a56e-3efbbdf5907e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainSequence(kutils.Sequence):\n",
    "    def __init__(self, filenames, batch_size, patch_sizes, bands_count, len, label_dirs):\n",
    "        self.filenames = filenames\n",
    "        self.batch_size = batch_size\n",
    "        self.patch_sizes = patch_sizes  # 字典，包含每种图像和标签的补丁大小\n",
    "        self.bands_count = bands_count  # 字典，包含每种图像类型的波段数\n",
    "        self.len = len\n",
    "        self.label_dirs = label_dirs# 列表，包含标签的目录\n",
    "        self.read_dataset()\n",
    "\n",
    "    def read_dataset(self):\n",
    "        self.data = []\n",
    "        for filename in self.filenames:\n",
    "            # 读取和处理图像\n",
    "            s1_image_path = os.path.join(S1_IMAGE_DIR, filename)\n",
    "            s2_10_image_path = os.path.join(S2_10_IMAGE_DIR, filename)\n",
    "            s2_20_image_path = os.path.join(S2_20_IMAGE_DIR, filename)\n",
    "            gedi_image_path = os.path.join(GEDI_IMAGE_DIR, filename)\n",
    "            \n",
    "            #s1_image = read_and_preprocess_image(s1_image_path, normalise=True)\n",
    "            s1_image = read_and_preprocess_image(s1_image_path, is_complex=True)\n",
    "\n",
    "            \n",
    "            s2_10_image = read_and_preprocess_image(s2_10_image_path)\n",
    "            s2_20_image = read_and_preprocess_image(s2_20_image_path)\n",
    "            gedi_image = read_and_preprocess_image(gedi_image_path)\n",
    "            \n",
    "            # Pad each image according to its patch size\n",
    "            s1_image, _ = pad_image_to_patch_size(s1_image, self.patch_sizes['s1'])\n",
    "            s2_10_image, _ = pad_image_to_patch_size(s2_10_image, self.patch_sizes['s2_10'])\n",
    "            s2_20_image, _ = pad_image_to_patch_size(s2_20_image, self.patch_sizes['s2_20'])\n",
    "            gedi_image, _ = pad_image_to_patch_size(gedi_image, self.patch_sizes['gedi'])\n",
    "\n",
    "\n",
    "            images = {'s1': s1_image, 's2_10': s2_10_image, 's2_20':s2_20_image, 'gedi': gedi_image}\n",
    "\n",
    "            # 读取和处理标签\n",
    "            labels = []\n",
    "            for label_type in self.label_dirs:\n",
    "                label_path = os.path.join(BASE_DIR, label_type, filename)\n",
    "                label = read_single_band_image(label_path)\n",
    "                # 使用 label_type 作为键来获取对应的补丁大小\n",
    "                label, _ = pad_image_to_patch_size(label, self.patch_sizes[label_type])\n",
    "                labels.append(label)\n",
    "\n",
    "\n",
    "            self.data.append((images, labels))\n",
    "    \n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        # 打乱数据\n",
    "        np.random.shuffle(self.data)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = {key: np.empty((self.batch_size, *self.patch_sizes[key], self.bands_count[key])) for key in ['s1', 's2_10', 's2_20', 'gedi']}\n",
    "        batch_y = [np.empty((self.batch_size, *self.patch_sizes[label_dir], 1)) for label_dir in self.label_dirs]\n",
    "\n",
    "        for patch_index in range(self.batch_size):\n",
    "            images, labels = self.sample_image()\n",
    "\n",
    "            # 基于参考图像（例如s1）计算采样起始点的比例\n",
    "            ref_image = images['s1']\n",
    "            y_ratio, x_ratio = self.calculate_sampling_start_point(ref_image, self.patch_sizes['s1'])\n",
    "\n",
    "            for key, image in images.items():\n",
    "                patch_size = self.patch_sizes[key]\n",
    "                batch_x[key][patch_index] = self.sample_patch(image, patch_size, y_ratio, x_ratio).astype(np.float32)\n",
    "\n",
    "            for i, label_dir in enumerate(self.label_dirs):\n",
    "                label = labels[i]\n",
    "                label_patch_size = self.patch_sizes[label_dir]\n",
    "                batch_y[i][patch_index] = self.sample_patch(label, label_patch_size, y_ratio, x_ratio).astype(np.float32)\n",
    "     \n",
    "        batch_x_tensors = {key: tf.convert_to_tensor(batch_x[key], dtype=tf.float32) for key in batch_x}\n",
    "        batch_y_tensors = [tf.convert_to_tensor(label_batch, dtype=tf.float32) for label_batch in batch_y]\n",
    "\n",
    "        return batch_x_tensors, batch_y_tensors\n",
    "\n",
    "    def sample_image(self):\n",
    "        # 随机选择一个图像和标签集\n",
    "        image_index = np.random.choice(len(self.data))\n",
    "        selected_data = self.data[image_index]\n",
    "        images = selected_data[0]  # 第一个元素是图像的字典\n",
    "        labels = selected_data[1]  # 第二个元素是标签的列表\n",
    "        # 打印选中的image_index\n",
    "        #print(\"Selected image index:\", image_index)\n",
    "        return images, labels  # 返回图像字典和标签列表\n",
    "\n",
    "    def sample_patch(self, image, patch_size, y_ratio, x_ratio):\n",
    "        # 根据提供的比例和补丁大小采样补丁\n",
    "        height, width, _ = image.shape\n",
    "        y_start = int((height - patch_size[0]) * y_ratio)\n",
    "        x_start = int((width - patch_size[1]) * x_ratio)\n",
    "        return image[y_start:y_start + patch_size[0], x_start:x_start + patch_size[1], :]\n",
    "\n",
    "    def calculate_sampling_start_point(self, reference_image, reference_patch_size):\n",
    "        # 基于参考图像和参考补丁大小计算采样起始点的比例\n",
    "        height, width, _ = reference_image.shape\n",
    "        y_ratio = np.random.uniform(0, 1 - reference_patch_size[0] / height)\n",
    "        x_ratio = np.random.uniform(0, 1 - reference_patch_size[1] / width)\n",
    "        return y_ratio, x_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598367b1-13cf-4e20-88b8-9c83b9381d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = TrainSequence(TRAIN_IMAGES, BATCH_SIZE, patch_sizes, bands_count, 3400, label_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4fb6a1-f4e9-4a03-82f5-0a3199f49b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sequence =TrainSequence(VAL_IMAGES,BATCH_SIZE, patch_sizes, bands_count, 2000, label_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ead7d-82df-43cf-8558-fc64f4e8d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置输入尺寸\n",
    "input_shape_s1 = 224,224,6  # Sentinel-1 输入尺寸\n",
    "input_shape_s10 = 224,224,4  # Sentinel-2 输入尺寸\n",
    "input_shape_s20 = 112,112,6  # Sentinel-2 输入尺寸\n",
    "input_shape_gedi = 28, 28, 101  # GEDI 输入尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6db440-af6d-459b-b694-97dfb21cea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(input_shape_s1, input_shape_s10, input_shape_s20, input_shape_gedi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45cb51-0879-4461-a924-8640a28d0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd44d13-edad-41df-a1d1-d9eb79c36f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66fde5b1-3bb7-4a76-9991-e996dcb7b75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.vis_utils import plot_model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c656a24d-eb1b-4a06-868a-be7fcc63a0fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot_model(model, to_file='model_newresnet.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad65a97-eadd-4687-8381-608d046680c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.losses import MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e7e7d3-259c-436e-94c9-1e39479b9363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2600c8bc-5b91-455b-aaf9-57efd4206c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 自定义 R² 指标函数\n",
    "def r_squared(y_true, y_pred):\n",
    "    SS_res =  K.sum(K.square(y_true - y_pred)) \n",
    "    SS_tot = K.sum(K.square(y_true - K.mean(y_true))) \n",
    "    return (1 - SS_res/(SS_tot + K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09687c3d-5e1f-4b0e-8497-7bd6d2cb89d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def root_mean_squared_error(y_true, y_pred):\n",
    "    return keras.backend.sqrt(keras.backend.mean(keras.backend.square(y_pred - y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d83790-bcc6-4fee-9d6b-129c56e02ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = keras.optimizers.Adam(1e-2,  epsilon=1e-4)\n",
    "model.compile(optimizer=optimizer1, loss='mse',  metrics=[root_mean_squared_error,r_squared,'mae'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082b422b-5843-41f8-8e35-048a10f6cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "# 初始化回调函数\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',  # 监控的值\n",
    "    factor=0.1,          # 学习率减少的因子\n",
    "    patience=5,         # 在减少学习率之前，等待几个epoch\n",
    "    min_lr=0.0000001       # 学习率的下限\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882064df-5071-459a-b732-556f03944aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# 定义早停规则\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',  # 监控的指标，常见的有'val_loss'和'val_accuracy'\n",
    "    min_delta=0.01,  # 表示被监控指标的最小变化量，只有大于这个值时才认为模型有改善\n",
    "    patience=10,  # 指定在监控指标没有改善的情况下等待的epochs数量\n",
    "    verbose=1,  # 控制输出，1表示输出早停信息\n",
    "    mode='min',  # 在监控指标为'val_loss'时，我们希望其最小化，因此设置为'min'。如果监控指标为'val_accuracy'，则设置为'max'\n",
    "    restore_best_weights=True  # 当早停发生时，是否恢复到最好的模型权重\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06393a2b-7468-427b-b487-48bcb5d131c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "# 设置ModelCheckpoint回调函数来保存验证损失最小的模型权重\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath='/home/jovyan/private/thesis_data/code/final_code/weight/6_14/best_model_weights.h5',  # 保存文件的路径\n",
    "    save_weights_only=True,  # True表示只保存模型的权重，False则保存整个模型\n",
    "    monitor='val_loss',  # 被监控的数据\n",
    "    mode='min',  # 在'min'模式下，监控数据的减少被认为是改进\n",
    "    save_best_only=True  # True表示只保存在验证集上性能最好的模型\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf465795-5d86-4a4c-b962-492807fbfc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "history= model.fit(\n",
    "    train_sequence, \n",
    "    epochs=200,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=1,  \n",
    "    validation_data=val_sequence,\n",
    "    callbacks=[ model_checkpoint_callback,reduce_lr,early_stopping ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e975439d-e6c8-4e3c-8a7d-835b09527865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model training history\n",
    "fig, axs = plt.subplots(nrows=1, ncols=1, figsize=(10, 4))\n",
    "\n",
    "# 绘制损失曲线\n",
    "axs.set_title(\"Sample net training curve loss\")\n",
    "axs.plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "axs.plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "axs.legend()\n",
    "axs.set_ylabel(\"Loss\")\n",
    "axs.set_xlabel(\"Epoch\")\n",
    "\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3071b0aa-1df4-404b-b25d-ca85fbb55a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequence =TrainSequence(TEST_IMAGES,BATCH_SIZE, patch_sizes, bands_count, 1500, label_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61facd1-a8d4-4d79-bb7f-5bf7b3af4048",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(test_sequence, verbose=1)\n",
    "\n",
    "print(f\"\\nTest loss: {results[0]:.4f}\")\n",
    "print(f\"RMSE: {results[1]:.4f}\")\n",
    "print(f\"R2: {results[2]:.4f}\")\n",
    "print(f\"MAE: {results[3]:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25867ae7-5443-4545-b149-4081b151bd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST=[\"3_1.tif\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0659608-2ac8-4ed3-a308-56a418338d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_sizes1 = {\n",
    "    's1': (224, 224),\n",
    "    's2_10': (224, 224),\n",
    "    's2_20': (112, 112),\n",
    "    'gedi': (28, 28)\n",
    "}\n",
    "steps = {\n",
    "    's1': 224,  # 可以调整步长以控制重叠\n",
    "    's2_10': 224,\n",
    "    's2_20': 112,\n",
    "    'gedi': 28\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e66d33-e7ed-4024-b34b-d584b0075db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENE_IDX = 0\n",
    "s1_image_path = os.path.join(S1_IMAGE_DIR, TEST[SCENE_IDX])\n",
    "s2_10_image_path = os.path.join(S2_10_IMAGE_DIR,TEST[SCENE_IDX])\n",
    "s2_20_image_path = os.path.join(S2_20_IMAGE_DIR, TEST[SCENE_IDX])\n",
    "gedi_image_path = os.path.join(GEDI_IMAGE_DIR,TEST[SCENE_IDX])\n",
    "            \n",
    "            \n",
    "s1_image1 = read_and_preprocess_image(s1_image_path, is_complex=True)\n",
    "s2_10_image1 = read_and_preprocess_image(s2_10_image_path)\n",
    "s2_20_image1 = read_and_preprocess_image(s2_20_image_path)\n",
    "gedi_image1 = read_and_preprocess_image(gedi_image_path)\n",
    "\n",
    "# 组织图像输入\n",
    "images = {\n",
    "    's1': s1_image1,\n",
    "    's2_10': s2_10_image1,\n",
    "    's2_20': s2_20_image1,\n",
    "    'gedi': gedi_image1\n",
    "}\n",
    "\n",
    "\n",
    "label_250_path = os.path.join(LABEL_250_DIR, TEST[SCENE_IDX])\n",
    "label_250 = read_single_band_image(label_250_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9e4b81-5753-4804-b0c3-839eb1788288",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(s2_10_image1[:, :, 0], cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57391734-2d52-4e01-bcc2-5ad99ff9fbbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_patches(image, patch_size, step):\n",
    "    # 生成图像块\n",
    "    patches = []\n",
    "    positions = []  # 定义位置列表\n",
    "    rows = range(0, image.shape[0] - patch_size[0] + 1, step)\n",
    "    cols = range(0, image.shape[1] - patch_size[1] + 1, step)\n",
    "    for row in rows:\n",
    "        for col in cols:\n",
    "            patch = image[row:row + patch_size[0], col:col + patch_size[1], :]\n",
    "            patches.append(patch)\n",
    "            # 计算每个 patch 相对于第一个 patch 的相对位置\n",
    "            rel_row = row // step + 1\n",
    "            rel_col = col // step + 1\n",
    "            positions.append((rel_row, rel_col))  # 记录每个 patch 的相对位置\n",
    "\n",
    "    return np.array(patches),positions # 返回图像块和位置列表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445f5330-7b0a-46d2-8a08-22ac283141ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def prepare_patches(image, patch_size, step):\n",
    "#     # 生成补丁\n",
    "#     image,padding_info=pad_image_to_patch_size(image, patch_size)\n",
    "#     patches,positions = generate_patches(image, patch_size, step)\n",
    "    \n",
    "#     print(patches.shape)\n",
    "#     return patches,positions,padding_info  # 只取所需数量的补丁\n",
    "\n",
    "\n",
    "def prepare_patches(image, patch_size, step):\n",
    "    padded_image, padding_info = pad_image_to_patch_size(image, patch_size)\n",
    "    patches, positions = generate_patches(padded_image, patch_size, step)\n",
    "    return patches, positions, padding_info\n",
    "\n",
    "\n",
    "# 为每种图像准备补丁\n",
    "patches_s1,positions_s1,padding_info_s1 = prepare_patches(s1_image1, patch_sizes1['s1'], steps['s1'])\n",
    "\n",
    "patches_10,_,_ = prepare_patches(s2_10_image1, patch_sizes1['s2_10'], steps['s2_10'])\n",
    "\n",
    "patches_20,_,_ = prepare_patches(s2_20_image1, patch_sizes1['s2_20'], steps['s2_20'])\n",
    "patches_80,_,_ = prepare_patches(gedi_image1, patch_sizes1['gedi'], steps['gedi'])\n",
    "#label=pad_image_to_patch_size(label_250, (9,9))\n",
    "# 使用模型进行预测\n",
    "prediction = model.predict([patches_s1, patches_10, patches_20, patches_80])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca08f519-d0eb-4e43-98a6-2934d9de17ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_image_from_patches(patches, positions, padding_info, original_shape, patch_size):\n",
    "    padded_height, padded_width = padding_info['padded_height'], padding_info['padded_width']\n",
    "    reconstructed_image = np.zeros((padded_height, padded_width))\n",
    "\n",
    "    # 遍历所有补丁和位置\n",
    "    for patch, (rel_row, rel_col) in zip(patches, positions):\n",
    "        start_row = (rel_row - 1) * patch_size[0]\n",
    "        start_col = (rel_col - 1) * patch_size[1]\n",
    "\n",
    "        reconstructed_image[start_row:start_row + patch_size[0], start_col:start_col + patch_size[1]] = patch[..., 0]\n",
    "\n",
    "    # 裁剪填充过的图像以恢复到原始尺寸\n",
    "    top_pad, left_pad = padding_info['top_pad'], padding_info['left_pad']\n",
    "    final_image = reconstructed_image[top_pad:top_pad + original_shape[0], left_pad:left_pad + original_shape[1]]\n",
    "\n",
    "    return final_image\n",
    "# 准备补丁和获取填充信息\n",
    "label_250_padded, padding_info_250 = pad_image_to_patch_size(label_250, (9, 9))\n",
    "print(\"Padded shape:\", label_250_padded.shape)\n",
    "\n",
    "# 重建图像\n",
    "reconstructed = reconstruct_image_from_patches(prediction, positions_s1, padding_info_250, label_250.shape, (9, 9))\n",
    "print(\"Reconstructed shape:\", reconstructed.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46a11c1-9c28-4504-a6c3-f3b9f7f49960",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_250.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51d142d-9df4-4529-b2b6-c6053bc1facf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(24, 7))  # 创建一个包含3个子图的画布\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "axs[0].imshow(reconstructed)  # 显示第一个输出通道的数据\n",
    "axs[0].set_title(\"Prediction_250\")\n",
    "\n",
    "axs[1].imshow(label_250)\n",
    "axs[1].set_title(\"Groundtruth\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56b4f30-6f5f-47e6-a2f1-998e3b113a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "# 假设 `reconstructed` 是我们重建的图像数组\n",
    "# `label_250_path` 是原始GeoTIFF图像的路径\n",
    "\n",
    "# 读取原始图像的地理信息\n",
    "with rasterio.open(label_250_path) as src:\n",
    "    transform = src.transform  # 原始图像的变换信息\n",
    "    crs = src.crs  # 坐标参考系统\n",
    "\n",
    "# 保存重建的图像\n",
    "with rasterio.open(\n",
    "    'weight/5_25/result/3.tif',  # 输出文件名\n",
    "    'w',\n",
    "    driver='GTiff',  # GeoTIFF格式\n",
    "    height=reconstructed.shape[0],\n",
    "    width=reconstructed.shape[1],\n",
    "    count=1,  # 通道数\n",
    "    dtype=reconstructed.dtype,\n",
    "    crs=crs,  # 使用原始图像的坐标参考系统\n",
    "    transform=transform  # 使用原始图像的变换信息\n",
    ") as dst:\n",
    "    dst.write(reconstructed, 1)  # 写入数据到第一个通道\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
