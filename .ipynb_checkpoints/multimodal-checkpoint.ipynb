{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69879ea-c334-48be-81bb-71cc1c288762",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbf550a-ac6a-4af0-8df5-bae8c61ab70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e186a1b2-a1f9-460b-9782-86480dc98440",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4362a9-3b08-4cd5-b598-202d1069086e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276a8d4c-cfb1-4522-98fe-e3be71493cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.optimizers as optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cf52d0d-76f5-4169-a99f-15b203edb283",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.utils as kutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f67543-fb74-4c10-9322-5caf602a4384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a448afae-8eca-4080-bd78-b0372099f39b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a0d6d5-0552-4d2b-99e2-d66567e85aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7780987f-98ad-4ebd-9df2-e290724d999d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5688abaa-fcf4-4127-bfd5-718ac927d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3725b710-b714-4e25-999c-512b0da7fc52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b55d69b-7fb1-4504-ae64-1e83ee6ae2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf049ec9-5f02-4b68-a03c-c9acf90560ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b0bcc2-8d20-4790-8558-5e7e50330c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e9b236-84a5-43ba-91be-bbf5c500680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import losses\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f2490f-869e-4508-a641-472fd9434a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fusion import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5da5afb-9e0c-43f6-a076-618e6fc652ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import fusion  ######改成py！！！！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81b1426-509b-4458-95f9-56d8395aca17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####optical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dcb841a-3b21-4616-b826-ed6c9334a9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 定义数据集目录\n",
    "BASE_DIR = \"dataset\"\n",
    "# 假设您有三个不同的目录，分别存储不同类型的图像\n",
    "S1_IMAGE_DIR = os.path.join(BASE_DIR, \"sentinel1_images\")\n",
    "S2_10_IMAGE_DIR = os.path.join(BASE_DIR, \"sentinel2_10_images\")\n",
    "S2_20_IMAGE_DIR = os.path.join(BASE_DIR, \"sentinel2_20_images\")\n",
    "GEDI_IMAGE_DIR = os.path.join(BASE_DIR, \"gedi_images\")\n",
    "LABEL_250_DIR = os.path.join(BASE_DIR, \"LABEL_250_DIR\")\n",
    "LABEL_100_DIR = os.path.join(BASE_DIR, \"LABEL_100_DIR\")\n",
    "\n",
    "\n",
    "# 定义常量\n",
    "\n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 50\n",
    "STEPS = 200\n",
    "\n",
    "# 定义测试和验证图像的文件名\n",
    "# 假设每种类型的图像都有相同的命名方式\n",
    "TRAIN_IMAGES = [\"2.tif\", \"7.tif\", \"4.tif\", \"5.tif\", \"9.tif\"]\n",
    "VAL_IMAGES = [\"6.tif\", \"3.tif\"]\n",
    "TEST_IMAGES = [\"8.tif\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a31e4d1-3eab-4d46-8fc9-e6f3cf00a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_sizes = {\"s1\": (224, 224), \"s2_10\": (224, 224),\"s2_20\":(112,112), \"gedi\": (28, 28), \"LABEL_250_DIR\": (9, 9), \"LABEL_100_DIR\": (23, 23)}\n",
    "bands_count = {\"s1\": 6, \"s2_10\": 4,\"s2_20\":6,\"gedi\":5 }\n",
    "label_dirs = ['LABEL_250_DIR', 'LABEL_100_DIR']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0361438-023f-49ab-90ba-62c9996176cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####read multiband image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "010d1702-4dc2-4171-9c7c-37f349c1cbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def read_and_preprocess_image(image_path, normalise_percentiles=NORMALISE_PERCENTILES):\n",
    "#     with rasterio.open(image_path) as image_file:\n",
    "#         image_arr = image_file.read()  # Reads all bands\n",
    "#         if normalise_percentiles:\n",
    "#             for band in range(image_arr.shape[0]):\n",
    "#                 band_arr = image_arr[band]\n",
    "#                 min_value = np.percentile(band_arr, normalise_percentiles[0])\n",
    "#                 max_value = np.percentile(band_arr, normalise_percentiles[1])\n",
    "#                 image_arr[band] = (band_arr - min_value) / (max_value - min_value)\n",
    "#     return image_arr.transpose(1, 2, 0)  # Reorder dimensions to height x width x bands\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b9ee027-cf14-4162-aa85-4b9e8da745fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def apply_template(image_arr, template):\n",
    "#     template_mask = np.all(template == 0, axis=-1)  # 创建模板遮罩\n",
    "#     for band in range(image_arr.shape[0]):\n",
    "#         band_arr = image_arr[band, :, :]\n",
    "#         band_arr[template_mask] = 0  # 应用模板遮罩\n",
    "#         image_arr[band, :, :] = band_arr\n",
    "#     return image_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1398537c-4a34-45aa-9499-f94d047e7096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_preprocess_image(image_path, normalise_percentiles=(2, 98), is_complex=False):\n",
    "    with rasterio.open(image_path) as image_file:\n",
    "        image_arr = image_file.read()  # 以[通道, 高度, 宽度]格式读取所有波段\n",
    "       \n",
    "        image_arr[image_arr == image_file.nodata] = np.nan\n",
    "                # 如果提供了模板，则应用模板\n",
    "        # if template is not None:\n",
    "        #     image_arr = apply_template(image_arr, template)\n",
    "        \n",
    "        if normalise_percentiles:\n",
    "            for band in range(image_arr.shape[0]):\n",
    "                band_arr = image_arr[band, :, :]\n",
    "                min_value = np.nanpercentile(band_arr, normalise_percentiles[0])\n",
    "                max_value = np.nanpercentile(band_arr, normalise_percentiles[1])\n",
    "                if max_value - min_value > np.finfo(float).eps:\n",
    "                    image_arr[band, :, :] = (band_arr - min_value) / (max_value - min_value)\n",
    "                else:\n",
    "                    image_arr[band, :, :] = np.zeros_like(band_arr)\n",
    "                    \n",
    "                    \n",
    "        if is_complex:\n",
    "            # 对于复数数据的特殊处理\n",
    "            real_channel_1 = np.expand_dims(image_arr[0], axis=0)  # 第一个通道，扩展维度以便堆叠\n",
    "            imag_channel_1 = np.zeros_like(real_channel_1)  # 第一个通道的虚部，使用零填充\n",
    "            \n",
    "            complex_real = np.expand_dims(image_arr[1], axis=0)  # 第二个通道作为复数的实部\n",
    "            complex_imag = np.expand_dims(image_arr[2], axis=0)  # 第三个通道作为复数的虚部\n",
    "            \n",
    "            real_channel_4 = np.expand_dims(image_arr[3], axis=0)  # 第四个通道\n",
    "            imag_channel_4 = np.zeros_like(real_channel_4)  # 第四个通道的虚部，使用零填充\n",
    "            \n",
    "            # 沿通道轴堆叠以创建6个通道\n",
    "            image_arr = np.concatenate([real_channel_1, imag_channel_1, complex_real, complex_imag, real_channel_4, imag_channel_4], axis=0)\n",
    "\n",
    "        # 在返回之前将 NaN 和 Inf 转换为 0\n",
    "        # 此处 posinf 和 neginf 参数可用于指定用于替换正、负无穷的值；默认行为是用最大或最小的浮点数替换\n",
    "        image_arr = np.nan_to_num(image_arr, nan=0.0, posinf=None, neginf=None)\n",
    "\n",
    "    return image_arr.transpose(1, 2, 0)  # 重新排序维度为高度 x 宽度 x 通道\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41120f2c-d4e5-4211-bbe8-e1d215f8880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_single_band_image(image_path):\n",
    "    with rasterio.open(image_path) as image_file:\n",
    "        single_band_image = image_file.read(1)  # Reads the first band\n",
    "        \n",
    "    # if template is not None:\n",
    "    #     single_band_image = apply_template(single_band_image, template)\n",
    "    \n",
    "    return np.expand_dims(single_band_image, axis=-1)  # Adds a channel dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25db929-f949-48a2-8f9c-8efdb3c06264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function pads an image to the nearest size divisible by patch_size\n",
    "# def pad_image_to_patch_size(image, patch_size=PATCH_SIZE):\n",
    "#     height, width, _ = image.shape\n",
    "#     target_height = patch_size * (height // patch_size + (height % patch_size > 0))\n",
    "#     target_width = patch_size * (width // patch_size + (width % patch_size > 0))\n",
    "#     pad_height = (target_height - height) // 2\n",
    "#     pad_width = (target_width - width) // 2\n",
    "#     padded_image = np.pad(image, ((pad_height, target_height - height - pad_height),\n",
    "#                                   (pad_width, target_width - width - pad_width),\n",
    "#                                   (0, 0)), mode='constant', constant_values=0)\n",
    "#     return padded_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b1d849-272a-4131-96ab-7011035702cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####别忘了patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a504e62d-80ff-4e72-b0a4-3152510cb883",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_image_to_patch_size(image, patch_size):\n",
    "    height, width, depth = image.shape\n",
    "    patch_height, patch_width = patch_size  # 解包元组，分别获取补丁的高度和宽度\n",
    "\n",
    "    # 计算目标高度和宽度\n",
    "    target_height = patch_height * (height // patch_height + (1 if height % patch_height != 0 else 0))\n",
    "    target_width = patch_width * (width // patch_width + (1 if width % patch_width != 0 else 0))\n",
    "\n",
    "    # 计算填充量\n",
    "    pad_height = (target_height - height) // 2\n",
    "    pad_width = (target_width - width) // 2\n",
    "\n",
    "    # 创建填充后的图像\n",
    "    padded = np.zeros((target_height, target_width, depth), dtype=image.dtype)\n",
    "    padded[pad_height:pad_height + height, pad_width:pad_width + width, :] = image\n",
    "\n",
    "    return padded, (pad_height, pad_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5e9e41-3a55-43a2-adf5-28748da61a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainSequence(kutils.Sequence):\n",
    "    def __init__(self, filenames, batch_size, patch_sizes, bands_count, len, label_dirs):\n",
    "        self.filenames = filenames\n",
    "        self.batch_size = batch_size\n",
    "        self.patch_sizes = patch_sizes  # 字典，包含每种图像和标签的补丁大小\n",
    "        self.bands_count = bands_count  # 字典，包含每种图像类型的波段数\n",
    "        self.len = len\n",
    "        self.label_dirs = ['LABEL_250_DIR', 'LABEL_100_DIR']  # 列表，包含标签的目录\n",
    "        self.read_dataset()\n",
    "\n",
    "    def read_dataset(self):\n",
    "        self.data = []\n",
    "        for filename in self.filenames:\n",
    "            # 读取和处理图像\n",
    "            s1_image_path = os.path.join(S1_IMAGE_DIR, filename)\n",
    "            s2_10_image_path = os.path.join(S2_10_IMAGE_DIR, filename)\n",
    "            s2_20_image_path = os.path.join(S2_20_IMAGE_DIR, filename)\n",
    "            gedi_image_path = os.path.join(GEDI_IMAGE_DIR, filename)\n",
    "            \n",
    "            #s1_image = read_and_preprocess_image(s1_image_path, normalise=True)\n",
    "            s1_image = read_and_preprocess_image(s1_image_path, is_complex=True)\n",
    "\n",
    "            # 然后处理其他图像，并使用S1图像作为模板\n",
    "            s2_10_image = read_and_preprocess_image(s2_10_image_path)\n",
    "            s2_20_image = read_and_preprocess_image(s2_20_image_path)\n",
    "            gedi_image = read_and_preprocess_image(gedi_image_path)\n",
    "            \n",
    "            # Pad each image according to its patch size\n",
    "            s1_image, _ = pad_image_to_patch_size(s1_image, self.patch_sizes['s1'])\n",
    "            s2_10_image, _ = pad_image_to_patch_size(s2_10_image, self.patch_sizes['s2_10'])\n",
    "            s2_20_image, _ = pad_image_to_patch_size(s2_20_image, self.patch_sizes['s2_20'])\n",
    "            gedi_image, _ = pad_image_to_patch_size(gedi_image, self.patch_sizes['gedi'])\n",
    "\n",
    "\n",
    "            images = {'s1': s1_image, 's2_10': s2_10_image, 's2_20':s2_20_image, 'gedi': gedi_image}\n",
    "\n",
    "            # 读取和处理标签\n",
    "            labels = []\n",
    "            for label_type in self.label_dirs:\n",
    "                label_path = os.path.join(BASE_DIR, label_type, filename)\n",
    "                label = read_single_band_image(label_path)\n",
    "                # 使用 label_type 作为键来获取对应的补丁大小\n",
    "                label, _ = pad_image_to_patch_size(label, self.patch_sizes[label_type])\n",
    "                labels.append(label)\n",
    "\n",
    "\n",
    "            self.data.append((images, labels))\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = {key: np.empty((self.batch_size, *self.patch_sizes[key], self.bands_count[key])) for key in ['s1', 's2_10', 's2_20','gedi']}\n",
    "        batch_y = [np.empty((self.batch_size, *self.patch_sizes[label_dir], 1)) for label_dir in self.label_dirs]\n",
    "\n",
    "        for patch_index in range(self.batch_size):\n",
    "            images, labels = self.sample_image()\n",
    "            patch_images = {key: self.sample_patch(image, self.patch_sizes[key]) for key, image in images.items()}\n",
    "            patch_labels = [self.sample_patch(label, self.patch_sizes[label_dir]) for label, label_dir in zip(labels, self.label_dirs)]\n",
    "\n",
    "            for key in batch_x:\n",
    "                batch_x[key][patch_index] = patch_images[key]\n",
    "            for i, label in enumerate(patch_labels):\n",
    "                batch_y[i][patch_index] = label\n",
    "\n",
    "        return [batch_x[key] for key in batch_x], batch_y\n",
    "\n",
    "    def sample_image(self):\n",
    "        image_index = np.random.choice(len(self.data))\n",
    "        return self.data[image_index]\n",
    "\n",
    "    def sample_patch(self, image, patch_size):\n",
    "        height, width, _ = image.shape\n",
    "        y = np.random.choice(height - patch_size[0])\n",
    "        x = np.random.choice(width - patch_size[1])\n",
    "        return image[y:y + patch_size[0], x:x + patch_size[1], :]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598367b1-13cf-4e20-88b8-9c83b9381d9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = TrainSequence(TRAIN_IMAGES, BATCH_SIZE, patch_sizes, bands_count, STEPS, label_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77248a4b-9b35-4f67-b91e-da743ee5c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ValSequence(kutils.Sequence):\n",
    "    def __init__(self, filenames, batch_size, patch_sizes, bands_count, label_dirs):\n",
    "        self.filenames = filenames\n",
    "        self.batch_size = batch_size\n",
    "        self.patch_sizes = patch_sizes\n",
    "        self.bands_count = bands_count\n",
    "        self.label_dirs = label_dirs\n",
    "        self.len = 20600\n",
    "        self.read_dataset()\n",
    "        self.reset()\n",
    "\n",
    "    def read_dataset(self):\n",
    "        self.data = []\n",
    "        for filename in self.filenames:\n",
    "            # 读取和处理图像\n",
    "            s1_image_path = os.path.join(S1_IMAGE_DIR, filename)\n",
    "            s2_10_image_path = os.path.join(S2_10_IMAGE_DIR, filename)\n",
    "            s2_20_image_path = os.path.join(S2_20_IMAGE_DIR, filename)\n",
    "            gedi_image_path = os.path.join(GEDI_IMAGE_DIR, filename)\n",
    "            \n",
    "            s1_image = read_and_preprocess_image(s1_image_path, is_complex=True)\n",
    "            s2_10_image = read_and_preprocess_image(s2_10_image_path)\n",
    "            s2_20_image = read_and_preprocess_image(s2_20_image_path)\n",
    "            gedi_image = read_and_preprocess_image(gedi_image_path)\n",
    "            \n",
    "            # Pad each image according to its patch size\n",
    "            s1_image, _ = pad_image_to_patch_size(s1_image, self.patch_sizes['s1'])\n",
    "            s2_10_image, _ = pad_image_to_patch_size(s2_10_image, self.patch_sizes['s2_10'])\n",
    "            s2_20_image, _ = pad_image_to_patch_size(s2_20_image, self.patch_sizes['s2_20'])\n",
    "            gedi_image, _ = pad_image_to_patch_size(gedi_image, self.patch_sizes['gedi'])\n",
    "\n",
    "            images = {'s1': s1_image, 's2_10': s2_10_image, 's2_20':s2_20_image, 'gedi': gedi_image}\n",
    "\n",
    "            # Read and preprocess labels\n",
    "            labels = []\n",
    "            for label_type in self.label_dirs:\n",
    "                label_path = os.path.join(BASE_DIR, label_type, filename)\n",
    "                label = read_single_band_image(label_path)\n",
    "                label, _ = pad_image_to_patch_size(label, self.patch_sizes[label_type])\n",
    "                labels.append(label)\n",
    "                \n",
    "            self.data.append((images, labels))\n",
    "            # 计算每个影像的补丁数量逻辑（可能需要您根据具体情况调整）\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "\n",
    "    def sample_image(self):\n",
    "        if self.image_index >= len(self.data):\n",
    "            self.reset()\n",
    "        return self.data[self.image_index]\n",
    "\n",
    "    def sample_patch(self, image, patch_size, image_type):\n",
    "        height, width = image.shape[:2]\n",
    "        x, y = self.x[image_type], self.y[image_type]\n",
    "\n",
    "        if x + patch_size[1] > width:\n",
    "            x = 0\n",
    "            y += patch_size[0]\n",
    "        if y + patch_size[0] > height:\n",
    "            y = 0\n",
    "            x = 0\n",
    "            self.image_index += 1\n",
    "            if self.image_index >= len(self.data):\n",
    "                self.reset()\n",
    "                self.image_index = 0\n",
    "            image, _ = self.sample_image()\n",
    "\n",
    "        patch_image = image[y:y + patch_size[0], x:x + patch_size[1]]\n",
    "        self.x[image_type] = x + patch_size[1]\n",
    "        self.y[image_type] = y\n",
    "\n",
    "        return patch_image\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = {key: np.empty((self.batch_size, *self.patch_sizes[key], self.bands_count[key])) for key in ['s1', 's2_10', 's2_20', 'gedi']}\n",
    "        batch_y = [np.empty((self.batch_size, *self.patch_sizes[label_dir], 1)) for label_dir in self.label_dirs]\n",
    "\n",
    "        for patch_index in range(self.batch_size):\n",
    "            images, labels = self.sample_image()\n",
    "            patch_images = {key: self.sample_patch(images[key], self.patch_sizes[key], key) for key in images.keys()}\n",
    "\n",
    "            # 注意在这里，您需要保证labels列表和self.label_dirs列表的顺序一致，以确保标签和它们的尺寸对应\n",
    "            patch_labels = [self.sample_patch(labels[index], self.patch_sizes[label_dir], label_dir) for index, label_dir in enumerate(self.label_dirs)]\n",
    "\n",
    "            for key in batch_x.keys():\n",
    "                batch_x[key][patch_index, ...] = patch_images[key]\n",
    "            for i, patch_label in enumerate(patch_labels):\n",
    "                # 这里假设标签是单通道的，所以我们在最后添加一个新的轴以符合batch_y的形状预期\n",
    "                batch_y[i][patch_index, ...] = patch_label\n",
    "                \n",
    "        return [batch_x[key] for key in batch_x.keys()], batch_y\n",
    "\n",
    "\n",
    "        return [batch_x[key] for key in batch_x], batch_y        \n",
    "    def reset(self):\n",
    "        self.image_index = 0\n",
    "        self.x = {key: 0 for key in self.patch_sizes}  # Reset x coordinates for patch sampling\n",
    "        self.y = {key: 0 for key in self.patch_sizes}  # Reset y coordinates for patch sampling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31fe476-c3fa-4398-82fd-838e2ae0b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sequence = ValSequence(VAL_IMAGES, BATCH_SIZE, patch_sizes, bands_count, ['LABEL_250_DIR', 'LABEL_100_DIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "401ead7d-82df-43cf-8558-fc64f4e8d14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置输入尺寸\n",
    "input_shape_s1 = 224,224,6  # Sentinel-1 输入尺寸\n",
    "input_shape_s10 = 224,224,4  # Sentinel-2 输入尺寸\n",
    "input_shape_s20 = 112,112,6  # Sentinel-2 输入尺寸\n",
    "input_shape_gedi = 28, 28, 5  # GEDI 输入尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6db440-af6d-459b-b694-97dfb21cea4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(input_shape_s1, input_shape_s10, input_shape_s20, input_shape_gedi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e45cb51-0879-4461-a924-8640a28d0c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ce7cd-e7b1-46e9-be43-26b9b2eca278",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses1 = {\n",
    "    'output_250': 'mean_squared_error',  # 假设这是正确的层名称\n",
    "    'output_100': 'mean_squared_error'   # 确保这里没有多余的空格\n",
    "}\n",
    "loss_weights1 = {\n",
    "    'output_250': 0.8,\n",
    "    'output_100': 0.2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d83790-bcc6-4fee-9d6b-129c56e02ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = keras.optimizers.Adam(0.000000001, clipnorm=1.)\n",
    "model.compile(optimizer=optimizer1, loss=losses1, loss_weights=loss_weights1, metrics=['mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8471e586-f422-4f58-ada1-3a1f071674d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf465795-5d86-4a4c-b962-492807fbfc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "history= model.fit(\n",
    "    train_sequence, \n",
    "    epochs=EPOCHS,\n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=1, \n",
    "    validation_data=val_sequence\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e975439d-e6c8-4e3c-8a7d-835b09527865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot model training history\n",
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(10, 4))\n",
    "\n",
    "# 绘制损失曲线\n",
    "axs[0].set_title(\"Sample net training curve loss\")\n",
    "axs[0].plot(history.history[\"loss\"], label=\"Train Loss\")\n",
    "axs[0].plot(history.history[\"val_loss\"], label=\"Validation Loss\")\n",
    "axs[0].legend()\n",
    "axs[0].set_ylabel(\"Loss\")\n",
    "axs[0].set_xlabel(\"Epoch\")\n",
    "\n",
    "# 绘制 MSE 曲线\n",
    "axs[1].set_title(\"Sample net training curve MSE\")\n",
    "axs[1].plot(history.history[\"mse\"], label=\"Train MSE\")\n",
    "axs[1].plot(history.history[\"val_mse\"], label=\"Validation MSE\")\n",
    "axs[1].legend()\n",
    "axs[1].set_ylabel(\"MSE\")\n",
    "axs[1].set_xlabel(\"Epoch\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d65be8bf-2d09-4e02-b250-ab39e14770d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_sequence.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6865df81-af9c-4711-9e21-ee6852bdacc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sequence = ValSequence(TEST_IMAGES, BATCH_SIZE, patch_sizes, bands_count, ['LABEL_250_DIR', 'LABEL_100_DIR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13887a3-327e-484c-8314-91fdd96ac7f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mse = model.evaluate(test_sequence, verbose=0)\n",
    "print(f\"\\nTest loss: {loss:.4f}\")\n",
    "print(f\"Mean Squared Error: {mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5203ab-c364-488b-82c6-b0d49fab45cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the weight of the trained network\n",
    "model.save_weights(\"unet_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eece171f-67a4-4412-a2ab-534935e2dab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_biomass_estimation(image, regression_model, patch_size, step=！！！):\n",
    "    original_height, original_width, _ = image.shape\n",
    "    padded, (pad_height, pad_width) = pad_image_to_patch_size(image, patch_size)\n",
    "    height, width, _ = padded.shape\n",
    "    \n",
    "    predictions = np.zeros((height, width))  # 单通道预测值\n",
    "    \n",
    "    row = 0\n",
    "    while row + patch_size <= height:\n",
    "        row_patches = []\n",
    "\n",
    "        col = 0 \n",
    "        while col + patch_size <= width:\n",
    "            patch = padded[row:row + patch_size, col:col + patch_size, :]\n",
    "            row_patches.append(patch)\n",
    "            col += step\n",
    "\n",
    "        batch = np.array(row_patches)\n",
    "        row_predictions = regression_model.predict(batch, verbose=0)\n",
    "\n",
    "        col, patch_idx = 0, 0\n",
    "        while col + patch_size <= width:\n",
    "            # 对于回归，我们可能直接取预测值而不是累加\n",
    "            predictions[row:row + patch_size, col:col + patch_size] = \\\n",
    "                row_predictions[patch_idx].reshape(patch_size, patch_size)\n",
    "            col += step\n",
    "            patch_idx += 1\n",
    "\n",
    "        row += step\n",
    "\n",
    "    predictions = predictions[\n",
    "        pad_height:pad_height + original_height,\n",
    "        pad_width:pad_width + original_width\n",
    "    ]\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9810690-f947-4d87-9904-df66928f497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENE_IDX = 0\n",
    "image_path = os.path.join(IMAGE_DIR, VAL_IMAGES[SCENE_IDX])\n",
    "label_path = os.path.join(LABEL_DIR, VAL_IMAGES[SCENE_IDX])\n",
    "\n",
    "image = read_image(image_path, normalise=True)\n",
    "label = map_classes(read_image(label_path))\n",
    "\n",
    "prediction = apply_segmentation_with_fcn(image, model)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(16, 7))\n",
    "\n",
    "axs[0].imshow(image[:, :, [2, 1, 0]])\n",
    "axs[0].set_title(\"Satellite image\")\n",
    "axs[1].imshow(label[:, :, 0])\n",
    "axs[1].set_title(\"Groundtruth\")\n",
    "axs[2].imshow(prediction)\n",
    "axs[2].set_title(\"U-Net prediction\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0c23b1-31e6-43b7-9a8f-b4cf7b7ede67",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCENE_IDX = 1\n",
    "image_path = os.path.join(IMAGE_DIR, VAL_IMAGES[SCENE_IDX])\n",
    "label_path = os.path.join(LABEL_DIR, VAL_IMAGES[SCENE_IDX])\n",
    "\n",
    "image = read_image(image_path, normalise=True)\n",
    "label = map_classes(read_image(label_path))\n",
    "\n",
    "prediction = apply_segmentation_with_fcn(image, model)\n",
    "\n",
    "fig, axs = plt.subplots(nrows=1, ncols=3, figsize=(16, 7))\n",
    "\n",
    "axs[0].imshow(image[:, :, [2, 1, 0]])\n",
    "axs[0].set_title(\"Satellite image\")\n",
    "axs[1].imshow(label[:, :, 0])\n",
    "axs[1].set_title(\"Groundtruth\")\n",
    "axs[2].imshow(prediction)\n",
    "axs[2].set_title(\"U-Net prediction\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696a9310-48fe-4955-a5c0-1a0ede1b06d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3269cdb-f739-424c-a981-0fd5c4ac7344",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
